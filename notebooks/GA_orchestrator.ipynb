{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3149cdb0",
      "metadata": {},
      "source": [
        "# GSM8K GA Orchestrator\n",
        "End-to-end experiment runner and live monitor (population=50, 30 generations)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ed4a0c8e",
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'src'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Bootstrap config and environment\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_config\n\u001b[32m      3\u001b[39m cfg = load_config()\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mUsing provider=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg.model_provider\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, model=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg.model_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, temp=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg.temperature\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, max_tokens=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg.max_tokens\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'src'"
          ]
        }
      ],
      "source": [
        "# Bootstrap config and environment\n",
        "import sys, os, pathlib\n",
        "# Ensure project root (with src/) is on sys.path\n",
        "candidates = [pathlib.Path.cwd(), pathlib.Path.cwd().parent, pathlib.Path.cwd().parent.parent]\n",
        "for c in candidates:\n",
        "    if (c / 'src').exists():\n",
        "        sys.path.insert(0, str(c))\n",
        "        break\n",
        "from src.utils.config import load_config\n",
        "cfg = load_config()\n",
        "print(f'Using provider={cfg.model_provider}, model={cfg.model_name}, temp={cfg.temperature}, max_tokens={cfg.max_tokens}')\n",
        "print('Paths:', cfg.paths)\n",
        "print('Population size (config):', cfg.raw['population']['population_size'], 'Max generations:', cfg.raw['population']['max_generations'])\n",
        "print('Concurrency limit:', cfg.raw['evaluation']['concurrency_limit'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79145124",
      "metadata": {},
      "source": [
        "## Data: Ensure GSM8K subsets exist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf20594e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "required = ['data/gsm8k_primary_eval.jsonl','data/gsm8k_validation.jsonl','data/gsm8k_final_test.jsonl']\n",
        "for p in required:\n",
        "    print(f'Found {p}:', os.path.exists(p))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "989cda28",
      "metadata": {},
      "source": [
        "## Seeds: curated 50 prompts preview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3dfb356",
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.genetics.seeds import SEED_PROMPTS\n",
        "print('Curated seeds:', len(SEED_PROMPTS))\n",
        "for i, s in enumerate(SEED_PROMPTS[:5]):\n",
        "    print(f'{i+1}.', s[:120])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c262f360",
      "metadata": {},
      "source": [
        "## Run full 30-generation experiment (population=50) with live progress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4373604",
      "metadata": {},
      "outputs": [],
      "source": [
        "import threading, time, json\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output, display\n",
        "from src.genetics.controller import evolve\n",
        "metrics_path = cfg.paths.get('logs','data/results/logs') + '/metrics.jsonl'\n",
        "# Start evolution in background thread\n",
        "def _run():\n",
        "    evolve()\n",
        "t = threading.Thread(target=_run)\n",
        "t.start()\n",
        "# Live monitor loop\n",
        "def read_metrics(path):\n",
        "    gens, bests, avgs, divs, hits, calls = [], [], [], [], [], []\n",
        "    best_text = None\n",
        "    if not os.path.exists(path):\n",
        "        return gens, bests, avgs, divs, hits, calls, best_text\n",
        "    with open(path, 'r') as f:\n",
        "        for line in f:\n",
        "            r = json.loads(line)\n",
        "            gens.append(r.get('generation'))\n",
        "            bests.append(r.get('best_fitness'))\n",
        "            avgs.append(r.get('avg_fitness'))\n",
        "            divs.append(r.get('diversity'))\n",
        "            hits.append(r.get('cache_hit_rate', 0.0))\n",
        "            calls.append(r.get('api_calls', 0))\n",
        "            bt = r.get('best_text')\n",
        "            if bt: best_text = bt\n",
        "    return gens, bests, avgs, divs, hits, calls, best_text\n",
        "while t.is_alive():\n",
        "    clear_output(wait=True)\n",
        "    print('Running evolution...')\n",
        "    gens, bests, avgs, divs, hits, calls, best_text = read_metrics(metrics_path)\n",
        "    if gens:\n",
        "        fig, axs = plt.subplots(2, 3, figsize=(14,8))\n",
        "        axs[0,0].plot(gens, bests); axs[0,0].set_title('Best Fitness');\n",
        "        axs[0,1].plot(gens, avgs); axs[0,1].set_title('Average Fitness');\n",
        "        axs[0,2].plot(gens, divs); axs[0,2].set_title('Diversity');\n",
        "        axs[1,0].plot(gens, hits); axs[1,0].set_title('Cache Hit Rate');\n",
        "        axs[1,1].plot(gens, calls); axs[1,1].set_title('API Calls');\n",
        "        axs[1,2].axis('off');\n",
        "        plt.tight_layout(); display(fig); plt.close(fig)\n",
        "        if best_text:\n",
        "            print('\n",
        "Current best prompt preview:\n",
        "', best_text[:400])\n",
        "    else:\n",
        "        print('Waiting for metrics...')\n",
        "    time.sleep(5)\n",
        "# Final draw\n",
        "clear_output(wait=True)\n",
        "gens, bests, avgs, divs, hits, calls, best_text = read_metrics(metrics_path)\n",
        "print('Evolution finished. Generations logged:', len(gens))\n",
        "if gens:\n",
        "    fig, axs = plt.subplots(2, 3, figsize=(14,8))\n",
        "    axs[0,0].plot(gens, bests); axs[0,0].set_title('Best Fitness');\n",
        "    axs[0,1].plot(gens, avgs); axs[0,1].set_title('Average Fitness');\n",
        "    axs[0,2].plot(gens, divs); axs[0,2].set_title('Diversity');\n",
        "    axs[1,0].plot(gens, hits); axs[1,0].set_title('Cache Hit Rate');\n",
        "    axs[1,1].plot(gens, calls); axs[1,1].set_title('API Calls');\n",
        "    axs[1,2].axis('off'); plt.tight_layout(); display(fig); plt.close(fig)\n",
        "    if best_text:\n",
        "        print('\n",
        "Final best prompt (truncated):\n",
        "', best_text[:800])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0500e5d0",
      "metadata": {},
      "source": [
        "## Save final results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d9f5249",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Copy best prompt text to results directory if present in metrics\n",
        "import os, json, shutil\n",
        "metrics_path = cfg.paths.get('logs','data/results/logs') + '/metrics.jsonl'\n",
        "best_text = None\n",
        "if os.path.exists(metrics_path):\n",
        "    with open(metrics_path, 'r') as f:\n",
        "        for line in f:\n",
        "            r = json.loads(line); bt = r.get('best_text');\n",
        "            if bt: best_text = bt\n",
        "if best_text:\n",
        "    outp = os.path.join(cfg.paths.get('results','data/results'), 'best_prompt_final.txt')\n",
        "    with open(outp, 'w') as f: f.write(best_text)\n",
        "    print('Saved final best prompt to', outp)\n",
        "else:\n",
        "    print('No best_text found in metrics.')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
