{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3149cdb0",
      "metadata": {},
      "source": [
        "# GSM8K GA Orchestrator\n",
        "End-to-end experiment runner and live monitor (population=50, 30 generations)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ed4a0c8e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded config for provider=openai, model=gpt-4o, temp=0.0, max_tokens=200\n",
            "Using provider=openai, model=gpt-4o, temp=0.0, max_tokens=200\n",
            "Project root: /Users/Odyssey/Projects/genetic-prompt\n",
            "Paths: {'data_root': 'data', 'gsm8k_cache': 'data/gsm8k_raw', 'checkpoints': 'data/checkpoints', 'results': 'data/results', 'embeddings': 'data/embeddings', 'logs': 'data/results/logs'}\n",
            "Population size (config): 50 Max generations: 30\n",
            "Concurrency limit: 5\n"
          ]
        }
      ],
      "source": [
        "# Bootstrap config and environment\n",
        "import sys, os, pathlib\n",
        "# Ensure project root (with src/) is on sys.path\n",
        "candidates = [pathlib.Path.cwd(), pathlib.Path.cwd().parent, pathlib.Path.cwd().parent.parent]\n",
        "PROJECT_ROOT = None\n",
        "for c in candidates:\n",
        "    if (c / 'src').exists():\n",
        "        sys.path.insert(0, str(c))\n",
        "        PROJECT_ROOT = c\n",
        "        break\n",
        "from src.utils.config import load_config\n",
        "cfg = load_config()\n",
        "print(f'Using provider={cfg.model_provider}, model={cfg.model_name}, temp={cfg.temperature}, max_tokens={cfg.max_tokens}')\n",
        "print('Project root:', PROJECT_ROOT)\n",
        "print('Paths:', cfg.paths)\n",
        "print('Population size (config):', cfg.raw['population']['population_size'], 'Max generations:', cfg.raw['population']['max_generations'])\n",
        "print('Concurrency limit:', cfg.raw['evaluation']['concurrency_limit'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79145124",
      "metadata": {},
      "source": [
        "## Data: Ensure GSM8K subsets exist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "bf20594e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found data/gsm8k_primary_eval.jsonl: True\n",
            "Found data/gsm8k_validation.jsonl: True\n",
            "Found data/gsm8k_final_test.jsonl: True\n"
          ]
        }
      ],
      "source": [
        "import os, sys, pathlib, subprocess as sp\n",
        "def abspath(rel):\n",
        "    base = PROJECT_ROOT if PROJECT_ROOT else pathlib.Path.cwd()\n",
        "    return str((base / rel).resolve())\n",
        "required_rel = ['data/gsm8k_primary_eval.jsonl','data/gsm8k_validation.jsonl','data/gsm8k_final_test.jsonl']\n",
        "required_abs = [abspath(p) for p in required_rel]\n",
        "for rel, abs_p in zip(required_rel, required_abs):\n",
        "    print(f'Found {rel}:', os.path.exists(abs_p))\n",
        "missing = [p for p in required_abs if not os.path.exists(p)]\n",
        "if missing:\n",
        "    print('Missing subsets; downloading dataset and creating subsets...')\n",
        "    sp.run([sys.executable, str((PROJECT_ROOT/'scripts'/'download_data.py').resolve()), '--out', str((PROJECT_ROOT/'data'/'gsm8k_raw').resolve())], check=True, cwd=str(PROJECT_ROOT))\n",
        "    sp.run([sys.executable, str((PROJECT_ROOT/'scripts'/'create_subsets.py').resolve()), '--data', str((PROJECT_ROOT/'data'/'gsm8k_raw').resolve()), '--out', str((PROJECT_ROOT/'data').resolve()), '--primary','100','--validation','100','--final','200','--seed_primary','42','--seed_validation','43','--seed_final','44'], check=True, cwd=str(PROJECT_ROOT))\n",
        "    required_abs = [abspath(p) for p in required_rel]\n",
        "    for rel, abs_p in zip(required_rel, required_abs):\n",
        "        print(f'Found {rel}:', os.path.exists(abs_p))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "989cda28",
      "metadata": {},
      "source": [
        "## Seeds: curated 50 prompts preview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f3dfb356",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Curated seeds: 50\n",
            "1. Let's solve this step by step, writing each calculation clearly before the final answer.\n",
            "2. Think carefully: restate the problem, identify knowns and unknowns, and plan the steps.\n",
            "3. Break the problem into parts: what is asked, what is given, and which operations are needed.\n",
            "4. Use units consistently and show intermediate results with units.\n",
            "5. List relevant quantities, then compute them in order, verifying each intermediate value.\n"
          ]
        }
      ],
      "source": [
        "from src.genetics.seeds import SEED_PROMPTS\n",
        "print('Curated seeds:', len(SEED_PROMPTS))\n",
        "for i, s in enumerate(SEED_PROMPTS[:5]):\n",
        "    print(f'{i+1}.', s[:120])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c262f360",
      "metadata": {},
      "source": [
        "## Run full 30-generation experiment (population=50) with live progress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a4373604",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running evolution...\n",
            "Waiting for metrics...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 47\u001b[39m\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     46\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mWaiting for metrics...\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# Final draw\u001b[39;00m\n\u001b[32m     49\u001b[39m clear_output(wait=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "import threading, time, json, os\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output, display, HTML\n",
        "from datetime import datetime, timedelta\n",
        "from src.genetics.controller import evolve\n",
        "\n",
        "# Ensure logs directory exists and get absolute path\n",
        "logs_dir = cfg.paths.get('logs','data/results/logs')\n",
        "if not os.path.isabs(logs_dir):\n",
        "    logs_dir = str((PROJECT_ROOT / logs_dir).resolve())\n",
        "os.makedirs(logs_dir, exist_ok=True)\n",
        "metrics_path = os.path.join(logs_dir, 'metrics.jsonl')\n",
        "print(f'Metrics will be logged to: {metrics_path}')\n",
        "\n",
        "# Global variables for monitoring\n",
        "start_time = time.time()\n",
        "max_generations = cfg.raw['population']['max_generations']\n",
        "evolution_error = None\n",
        "\n",
        "# Enhanced evolution runner with error handling\n",
        "def _run():\n",
        "    global evolution_error\n",
        "    try:\n",
        "        print('Evolution thread started...')\n",
        "        result = evolve()\n",
        "        print('Evolution completed successfully!')\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        evolution_error = str(e)\n",
        "        print(f'Evolution failed with error: {e}')\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "# Start evolution in background thread\n",
        "t = threading.Thread(target=_run)\n",
        "t.start()\n",
        "# Enhanced metrics reader with comprehensive data extraction\n",
        "def read_metrics(path):\n",
        "    gens, bests, avgs, divs, hits, calls, accuracies, timestamps = [], [], [], [], [], [], [], []\n",
        "    best_text = None\n",
        "    latest_gen = -1\n",
        "    if not os.path.exists(path):\n",
        "        return gens, bests, avgs, divs, hits, calls, accuracies, timestamps, best_text, latest_gen\n",
        "    try:\n",
        "        with open(path, 'r') as f:\n",
        "            for line in f:\n",
        "                if line.strip():\n",
        "                    r = json.loads(line)\n",
        "                    gen = r.get('generation', 0)\n",
        "                    gens.append(gen)\n",
        "                    bests.append(r.get('best_fitness', 0.0))\n",
        "                    avgs.append(r.get('avg_fitness', 0.0))\n",
        "                    divs.append(r.get('diversity', 0.0))\n",
        "                    hits.append(r.get('cache_hit_rate', 0.0))\n",
        "                    calls.append(r.get('api_calls', 0))\n",
        "                    accuracies.append(r.get('best_accuracy', 0.0))\n",
        "                    timestamps.append(r.get('timestamp', time.time()))\n",
        "                    bt = r.get('best_text')\n",
        "                    if bt: best_text = bt\n",
        "                    latest_gen = max(latest_gen, gen)\n",
        "    except Exception as e:\n",
        "        print(f'Error reading metrics: {e}')\n",
        "    return gens, bests, avgs, divs, hits, calls, accuracies, timestamps, best_text, latest_gen\n",
        "\n",
        "# Progress calculation helpers\n",
        "def format_time(seconds):\n",
        "    if seconds < 60:\n",
        "        return f'{seconds:.0f}s'\n",
        "    elif seconds < 3600:\n",
        "        return f'{seconds//60:.0f}m {seconds%60:.0f}s'\n",
        "    else:\n",
        "        return f'{seconds//3600:.0f}h {(seconds%3600)//60:.0f}m'\n",
        "\n",
        "def estimate_remaining_time(current_gen, total_gens, elapsed_time):\n",
        "    if current_gen <= 0:\n",
        "        return 'Calculating...'\n",
        "    avg_time_per_gen = elapsed_time / (current_gen + 1)\n",
        "    remaining_gens = total_gens - current_gen - 1\n",
        "    remaining_time = avg_time_per_gen * remaining_gens\n",
        "    return format_time(remaining_time)\n",
        "\n",
        "# Enhanced live monitoring loop with comprehensive progress display\n",
        "refresh_interval = 3  # seconds\n",
        "last_update_time = time.time()\n",
        "\n",
        "while t.is_alive():\n",
        "    clear_output(wait=True)\n",
        "    current_time = time.time()\n",
        "    elapsed = current_time - start_time\n",
        "    \n",
        "    # Check for evolution errors\n",
        "    if evolution_error:\n",
        "        print(f'❌ Evolution failed: {evolution_error}')\n",
        "        break\n",
        "    \n",
        "    # Read current metrics\n",
        "    gens, bests, avgs, divs, hits, calls, accuracies, timestamps, best_text, latest_gen = read_metrics(metrics_path)\n",
        "    \n",
        "    # Progress header\n",
        "    progress_pct = ((latest_gen + 1) / max_generations * 100) if latest_gen >= 0 else 0\n",
        "    remaining_time = estimate_remaining_time(latest_gen, max_generations, elapsed)\n",
        "    \n",
        "    print('🧬 GSM8K Genetic Algorithm - Live Evolution Monitor')\n",
        "    print('=' * 60)\n",
        "    print(f'📊 Progress: Generation {latest_gen + 1}/{max_generations} ({progress_pct:.1f}%)')\n",
        "    print(f'⏱️  Elapsed: {format_time(elapsed)} | Remaining: {remaining_time}')\n",
        "    \n",
        "    if gens and len(gens) > 0:\n",
        "        # Current statistics\n",
        "        current_best = bests[-1] if bests else 0.0\n",
        "        current_avg = avgs[-1] if avgs else 0.0\n",
        "        current_acc = accuracies[-1] if accuracies else 0.0\n",
        "        current_div = divs[-1] if divs else 0.0\n",
        "        current_hit_rate = hits[-1] if hits else 0.0\n",
        "        total_api_calls = calls[-1] if calls else 0\n",
        "        \n",
        "        print(f'🎯 Best Fitness: {current_best:.4f} | Accuracy: {current_acc:.4f}')\n",
        "        print(f'📈 Avg Fitness: {current_avg:.4f} | Diversity: {current_div:.4f}')\n",
        "        print(f'🔄 API Calls: {total_api_calls} | Cache Hit Rate: {current_hit_rate:.2%}')\n",
        "        \n",
        "        # Performance trends\n",
        "        if len(bests) >= 2:\n",
        "            fitness_trend = bests[-1] - bests[-2]\n",
        "            trend_icon = '📈' if fitness_trend > 0 else '📉' if fitness_trend < 0 else '➡️'\n",
        "            print(f'{trend_icon} Fitness Trend: {fitness_trend:+.4f}')\n",
        "        \n",
        "        # Create comprehensive visualization\n",
        "        fig, axs = plt.subplots(2, 3, figsize=(16, 10))\n",
        "        fig.suptitle(f'Evolution Progress - Generation {latest_gen + 1}/{max_generations}', fontsize=16)\n",
        "        \n",
        "        # Fitness evolution\n",
        "        axs[0,0].plot(gens, bests, 'b-', linewidth=2, label='Best')\n",
        "        axs[0,0].plot(gens, avgs, 'r--', alpha=0.7, label='Average')\n",
        "        axs[0,0].set_title('Fitness Evolution')\n",
        "        axs[0,0].set_xlabel('Generation')\n",
        "        axs[0,0].set_ylabel('Fitness')\n",
        "        axs[0,0].legend()\n",
        "        axs[0,0].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Accuracy progression\n",
        "        axs[0,1].plot(gens, accuracies, 'g-', linewidth=2)\n",
        "        axs[0,1].set_title('Accuracy Progression')\n",
        "        axs[0,1].set_xlabel('Generation')\n",
        "        axs[0,1].set_ylabel('Accuracy')\n",
        "        axs[0,1].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Population diversity\n",
        "        axs[0,2].plot(gens, divs, 'm-', linewidth=2)\n",
        "        axs[0,2].set_title('Population Diversity')\n",
        "        axs[0,2].set_xlabel('Generation')\n",
        "        axs[0,2].set_ylabel('Diversity')\n",
        "        axs[0,2].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Cache performance\n",
        "        axs[1,0].plot(gens, hits, 'c-', linewidth=2)\n",
        "        axs[1,0].set_title('Cache Hit Rate')\n",
        "        axs[1,0].set_xlabel('Generation')\n",
        "        axs[1,0].set_ylabel('Hit Rate')\n",
        "        axs[1,0].grid(True, alpha=0.3)\n",
        "        \n",
        "        # API usage\n",
        "        axs[1,1].plot(gens, calls, 'orange', linewidth=2)\n",
        "        axs[1,1].set_title('Cumulative API Calls')\n",
        "        axs[1,1].set_xlabel('Generation')\n",
        "        axs[1,1].set_ylabel('API Calls')\n",
        "        axs[1,1].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Progress bar\n",
        "        axs[1,2].barh([0], [progress_pct], color='lightblue', alpha=0.7)\n",
        "        axs[1,2].set_xlim(0, 100)\n",
        "        axs[1,2].set_ylim(-0.5, 0.5)\n",
        "        axs[1,2].set_title(f'Progress: {progress_pct:.1f}%')\n",
        "        axs[1,2].set_xlabel('Completion %')\n",
        "        axs[1,2].set_yticks([])\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        display(fig)\n",
        "        plt.close(fig)\n",
        "        \n",
        "        # Show best prompt preview\n",
        "        if best_text:\n",
        "            print('\\n🏆 Current Best Prompt (preview):')\n",
        "            print('-' * 50)\n",
        "            print(best_text[:300] + ('...' if len(best_text) > 300 else ''))\n",
        "            print('-' * 50)\n",
        "    else:\n",
        "        print('⏳ Initializing evolution... Waiting for first generation metrics...')\n",
        "        print(f'📁 Monitoring: {metrics_path}')\n",
        "        if os.path.exists(metrics_path):\n",
        "            file_size = os.path.getsize(metrics_path)\n",
        "            print(f'📄 Metrics file exists ({file_size} bytes)')\n",
        "        else:\n",
        "            print('📄 Metrics file not yet created')\n",
        "    \n",
        "    print(f'\\n🔄 Last updated: {datetime.now().strftime(\"%H:%M:%S\")} | Next refresh in {refresh_interval}s')\n",
        "    time.sleep(refresh_interval)\n",
        "\n",
        "# Final draw\n",
        "clear_output(wait=True)\n",
        "gens, bests, avgs, divs, hits, calls, accuracies, timestamps, best_text, latest_gen = read_metrics(metrics_path)\n",
        "print('Evolution finished. Generations logged:', len(gens))\n",
        "if gens:\n",
        "    fig, axs = plt.subplots(2, 3, figsize=(14,8))\n",
        "    axs[0,0].plot(gens, bests); axs[0,0].set_title('Best Fitness');\n",
        "    axs[0,1].plot(gens, avgs); axs[0,1].set_title('Average Fitness');\n",
        "    axs[0,2].plot(gens, divs); axs[0,2].set_title('Diversity');\n",
        "    axs[1,0].plot(gens, hits); axs[1,0].set_title('Cache Hit Rate');\n",
        "    axs[1,1].plot(gens, calls); axs[1,1].set_title('API Calls');\n",
        "    axs[1,2].axis('off'); plt.tight_layout(); display(fig); plt.close(fig)\n",
        "    if best_text:\n",
        "        print('\\nFinal best prompt (truncated):\\n', best_text[:800])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0500e5d0",
      "metadata": {},
      "source": [
        "## Save final results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9d9f5249",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No best_text found in metrics.\n"
          ]
        }
      ],
      "source": [
        "# Copy best prompt text to results directory if present in metrics\n",
        "import os, json, shutil\n",
        "metrics_path = cfg.paths.get('logs','data/results/logs') + '/metrics.jsonl'\n",
        "best_text = None\n",
        "if os.path.exists(metrics_path):\n",
        "    with open(metrics_path, 'r') as f:\n",
        "        for line in f:\n",
        "            r = json.loads(line); bt = r.get('best_text');\n",
        "            if bt: best_text = bt\n",
        "if best_text:\n",
        "    outp = os.path.join(cfg.paths.get('results','data/results'), 'best_prompt_final.txt')\n",
        "    with open(outp, 'w') as f: f.write(best_text)\n",
        "    print('Saved final best prompt to', outp)\n",
        "else:\n",
        "    print('No best_text found in metrics.')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
