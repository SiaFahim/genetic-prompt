{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3149cdb0",
      "metadata": {},
      "source": [
        "# GSM8K GA Orchestrator\n",
        "End-to-end experiment runner and live monitor (population=50, 30 generations)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ed4a0c8e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded config for provider=openai, model=gpt-4o, temp=0.0, max_tokens=200\n",
            "Using provider=openai, model=gpt-4o, temp=0.0, max_tokens=200\n",
            "Paths: {'data_root': 'data', 'gsm8k_cache': 'data/gsm8k_raw', 'checkpoints': 'data/checkpoints', 'results': 'data/results', 'embeddings': 'data/embeddings', 'logs': 'data/results/logs'}\n",
            "Population size (config): 50 Max generations: 30\n",
            "Concurrency limit: 5\n"
          ]
        }
      ],
      "source": [
        "# Bootstrap config and environment\n",
        "import sys, os, pathlib\n",
        "# Ensure project root (with src/) is on sys.path\n",
        "candidates = [pathlib.Path.cwd(), pathlib.Path.cwd().parent, pathlib.Path.cwd().parent.parent]\n",
        "PROJECT_ROOT = None\n",
        "for c in candidates:\n",
        "    if (c / 'src').exists():\n",
        "        sys.path.insert(0, str(c))\n",
        "        PROJECT_ROOT = c\n",
        "        break\n",
        "from src.utils.config import load_config\n",
        "cfg = load_config()\n",
        "print(f'Using provider={cfg.model_provider}, model={cfg.model_name}, temp={cfg.temperature}, max_tokens={cfg.max_tokens}')\n",
        "print('Project root:', PROJECT_ROOT)\n",
        "print('Paths:', cfg.paths)\n",
        "print('Population size (config):', cfg.raw['population']['population_size'], 'Max generations:', cfg.raw['population']['max_generations'])\n",
        "print('Concurrency limit:', cfg.raw['evaluation']['concurrency_limit'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79145124",
      "metadata": {},
      "source": [
        "## Data: Ensure GSM8K subsets exist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "bf20594e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found data/gsm8k_primary_eval.jsonl: False\n",
            "Found data/gsm8k_validation.jsonl: False\n",
            "Found data/gsm8k_final_test.jsonl: False\n"
          ]
        }
      ],
      "source": [
        "import os, sys, pathlib, subprocess as sp\n",
        "def abspath(rel):\n",
        "    base = PROJECT_ROOT if PROJECT_ROOT else pathlib.Path.cwd()\n",
        "    return str((base / rel).resolve())\n",
        "required_rel = ['data/gsm8k_primary_eval.jsonl','data/gsm8k_validation.jsonl','data/gsm8k_final_test.jsonl']\n",
        "required_abs = [abspath(p) for p in required_rel]\n",
        "for rel, abs_p in zip(required_rel, required_abs):\n",
        "    print(f'Found {rel}:', os.path.exists(abs_p))\n",
        "missing = [p for p in required_abs if not os.path.exists(p)]\n",
        "if missing:\n",
        "    print('Missing subsets; downloading dataset and creating subsets...')\n",
        "    sp.run([sys.executable, str((PROJECT_ROOT/'scripts'/'download_data.py').resolve()), '--out', str((PROJECT_ROOT/'data'/'gsm8k_raw').resolve())], check=True, cwd=str(PROJECT_ROOT))\n",
        "    sp.run([sys.executable, str((PROJECT_ROOT/'scripts'/'create_subsets.py').resolve()), '--data', str((PROJECT_ROOT/'data'/'gsm8k_raw').resolve()), '--out', str((PROJECT_ROOT/'data').resolve()), '--primary','100','--validation','100','--final','200','--seed_primary','42','--seed_validation','43','--seed_final','44'], check=True, cwd=str(PROJECT_ROOT))\n",
        "    required_abs = [abspath(p) for p in required_rel]\n",
        "    for rel, abs_p in zip(required_rel, required_abs):\n",
        "        print(f'Found {rel}:', os.path.exists(abs_p))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "989cda28",
      "metadata": {},
      "source": [
        "## Seeds: curated 50 prompts preview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3dfb356",
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.genetics.seeds import SEED_PROMPTS\n",
        "print('Curated seeds:', len(SEED_PROMPTS))\n",
        "for i, s in enumerate(SEED_PROMPTS[:5]):\n",
        "    print(f'{i+1}.', s[:120])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c262f360",
      "metadata": {},
      "source": [
        "## Run full 30-generation experiment (population=50) with live progress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4373604",
      "metadata": {},
      "outputs": [],
      "source": [
        "import threading, time, json\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output, display\n",
        "from src.genetics.controller import evolve\n",
        "metrics_path = cfg.paths.get('logs','data/results/logs') + '/metrics.jsonl'\n",
        "# Start evolution in background thread\n",
        "def _run():\n",
        "    evolve()\n",
        "t = threading.Thread(target=_run)\n",
        "t.start()\n",
        "# Live monitor loop\n",
        "def read_metrics(path):\n",
        "    gens, bests, avgs, divs, hits, calls = [], [], [], [], [], []\n",
        "    best_text = None\n",
        "    if not os.path.exists(path):\n",
        "        return gens, bests, avgs, divs, hits, calls, best_text\n",
        "    with open(path, 'r') as f:\n",
        "        for line in f:\n",
        "            r = json.loads(line)\n",
        "            gens.append(r.get('generation'))\n",
        "            bests.append(r.get('best_fitness'))\n",
        "            avgs.append(r.get('avg_fitness'))\n",
        "            divs.append(r.get('diversity'))\n",
        "            hits.append(r.get('cache_hit_rate', 0.0))\n",
        "            calls.append(r.get('api_calls', 0))\n",
        "            bt = r.get('best_text')\n",
        "            if bt: best_text = bt\n",
        "    return gens, bests, avgs, divs, hits, calls, best_text\n",
        "while t.is_alive():\n",
        "    clear_output(wait=True)\n",
        "    print('Running evolution...')\n",
        "    gens, bests, avgs, divs, hits, calls, best_text = read_metrics(metrics_path)\n",
        "    if gens:\n",
        "        fig, axs = plt.subplots(2, 3, figsize=(14,8))\n",
        "        axs[0,0].plot(gens, bests); axs[0,0].set_title('Best Fitness');\n",
        "        axs[0,1].plot(gens, avgs); axs[0,1].set_title('Average Fitness');\n",
        "        axs[0,2].plot(gens, divs); axs[0,2].set_title('Diversity');\n",
        "        axs[1,0].plot(gens, hits); axs[1,0].set_title('Cache Hit Rate');\n",
        "        axs[1,1].plot(gens, calls); axs[1,1].set_title('API Calls');\n",
        "        axs[1,2].axis('off');\n",
        "        plt.tight_layout(); display(fig); plt.close(fig)\n",
        "        if best_text:\n",
        "            print('\n",
        "Current best prompt preview:\n",
        "', best_text[:400])\n",
        "    else:\n",
        "        print('Waiting for metrics...')\n",
        "    time.sleep(5)\n",
        "# Final draw\n",
        "clear_output(wait=True)\n",
        "gens, bests, avgs, divs, hits, calls, best_text = read_metrics(metrics_path)\n",
        "print('Evolution finished. Generations logged:', len(gens))\n",
        "if gens:\n",
        "    fig, axs = plt.subplots(2, 3, figsize=(14,8))\n",
        "    axs[0,0].plot(gens, bests); axs[0,0].set_title('Best Fitness');\n",
        "    axs[0,1].plot(gens, avgs); axs[0,1].set_title('Average Fitness');\n",
        "    axs[0,2].plot(gens, divs); axs[0,2].set_title('Diversity');\n",
        "    axs[1,0].plot(gens, hits); axs[1,0].set_title('Cache Hit Rate');\n",
        "    axs[1,1].plot(gens, calls); axs[1,1].set_title('API Calls');\n",
        "    axs[1,2].axis('off'); plt.tight_layout(); display(fig); plt.close(fig)\n",
        "    if best_text:\n",
        "        print('\n",
        "Final best prompt (truncated):\n",
        "', best_text[:800])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0500e5d0",
      "metadata": {},
      "source": [
        "## Save final results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d9f5249",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Copy best prompt text to results directory if present in metrics\n",
        "import os, json, shutil\n",
        "metrics_path = cfg.paths.get('logs','data/results/logs') + '/metrics.jsonl'\n",
        "best_text = None\n",
        "if os.path.exists(metrics_path):\n",
        "    with open(metrics_path, 'r') as f:\n",
        "        for line in f:\n",
        "            r = json.loads(line); bt = r.get('best_text');\n",
        "            if bt: best_text = bt\n",
        "if best_text:\n",
        "    outp = os.path.join(cfg.paths.get('results','data/results'), 'best_prompt_final.txt')\n",
        "    with open(outp, 'w') as f: f.write(best_text)\n",
        "    print('Saved final best prompt to', outp)\n",
        "else:\n",
        "    print('No best_text found in metrics.')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
