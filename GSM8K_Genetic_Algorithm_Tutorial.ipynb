{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GSM8K Genetic Algorithm for Prompt Evolution\n",
    "\n",
    "## Complete Tutorial: Evolving Mathematical Reasoning Prompts\n",
    "\n",
    "This notebook provides a tutorial for using genetic algorithms to evolve prompts for mathematical reasoning on the GSM8K dataset. You'll learn how to:\n",
    "\n",
    "- Set up the system and configure experiments\n",
    "- Run evolution experiments with real-time monitoring\n",
    "- Analyze results and interpret evolved prompts\n",
    "- Customize parameters for different research goals\n",
    "\n",
    "**Prerequisites:**\n",
    "- OpenAI API key (for GPT models)\n",
    "- Anthropic API key (for Claude models) - optional\n",
    "- Python environment with required dependencies\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. System Setup and Dependencies\n",
    "\n",
    "First, let's set up the environment and import all necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dependencies ready\n"
     ]
    }
   ],
   "source": [
    "# Install required packages if not already installed\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Uncomment and run if packages are not installed\n",
    "# install_package(\"openai>=1.0.0\")\n",
    "# install_package(\"anthropic\")\n",
    "# install_package(\"matplotlib\")\n",
    "# install_package(\"numpy\")\n",
    "# install_package(\"psutil\")\n",
    "\n",
    "print(\"✅ Dependencies ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Project root: /Users/Odyssey/Projects/genetic-prompt\n",
      "✅ System imports ready\n"
     ]
    }
   ],
   "source": [
    "# Import system modules\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to Python path\n",
    "project_root = Path.cwd()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "print(f\"📁 Project root: {project_root}\")\n",
    "print(\"✅ System imports ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. API Configuration\n",
    "\n",
    "Configure your API keys for accessing language models. The system supports both OpenAI and Anthropic models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Environment variables loaded from .env file\n",
      "🔑 OpenAI API Key: ✅ Set\n",
      "🔑 Anthropic API Key: ✅ Set\n"
     ]
    }
   ],
   "source": [
    "# Set up API keys\n",
    "# Option 1: Set environment variables (recommended)\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key-here\"\n",
    "# os.environ[\"ANTHROPIC_API_KEY\"] = \"your-anthropic-api-key-here\"\n",
    "\n",
    "# Option 2: Load from .env file\n",
    "env_file = project_root / \".env\"\n",
    "if env_file.exists():\n",
    "    with open(env_file, 'r') as f:\n",
    "        for line in f:\n",
    "            if '=' in line and not line.startswith('#'):\n",
    "                key, value = line.strip().split('=', 1)\n",
    "                os.environ[key] = value\n",
    "    print(\"✅ Environment variables loaded from .env file\")\n",
    "else:\n",
    "    print(\"⚠️  No .env file found. Please set API keys manually.\")\n",
    "\n",
    "# Verify API keys are set\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "anthropic_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "print(f\"🔑 OpenAI API Key: {'✅ Set' if openai_key else '❌ Not set'}\")\n",
    "print(f\"🔑 Anthropic API Key: {'✅ Set' if anthropic_key else '❌ Not set'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load System Components\n",
    "\n",
    "Now let's load all the genetic algorithm components we'll need for our experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Core components imported\n"
     ]
    }
   ],
   "source": [
    "# Import genetic algorithm components\n",
    "from src.utils.config import config\n",
    "from src.embeddings.vocabulary import vocabulary\n",
    "from src.seeds.seed_manager import SeedManager\n",
    "from src.config.experiment_configs import ConfigurationManager\n",
    "\n",
    "print(\"✅ Core components imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary loaded from /Users/Odyssey/Projects/genetic-prompt/data/embeddings/vocabulary.pkl\n",
      "Vocabulary size: 10004\n",
      "✅ Vocabulary loaded: 10004 tokens\n"
     ]
    }
   ],
   "source": [
    "# Initialize vocabulary\n",
    "vocab_file = config.get_data_dir() / \"embeddings\" / \"vocabulary.pkl\"\n",
    "\n",
    "if vocab_file.exists():\n",
    "    vocabulary.load_vocabulary(vocab_file)\n",
    "    print(f\"✅ Vocabulary loaded: {len(vocabulary.token_to_id)} tokens\")\n",
    "else:\n",
    "    print(\"📚 Creating vocabulary from scratch...\")\n",
    "    vocabulary._create_basic_vocabulary()\n",
    "    print(f\"✅ Basic vocabulary created: {len(vocabulary.token_to_id)} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Loaded collection 'test_collection' with 10 seeds\n",
      "📂 Loaded collection 'test_validation_collection' with 10 seeds\n",
      "🌱 Seed collection loaded: 50 high-quality prompts\n",
      "⚙️  Available presets: quick_test, standard, thorough, ablation_no_crossover, ablation_no_mutation, high_mutation, large_population, random_search\n"
     ]
    }
   ],
   "source": [
    "# Initialize seed manager and configuration manager\n",
    "seed_manager = SeedManager()\n",
    "config_manager = ConfigurationManager()\n",
    "\n",
    "# Load base seed collection\n",
    "base_seeds = seed_manager.get_base_seeds()\n",
    "print(f\"🌱 Seed collection loaded: {len(base_seeds)} high-quality prompts\")\n",
    "\n",
    "# Show available experiment presets\n",
    "presets = config_manager.list_presets()\n",
    "print(f\"⚙️  Available presets: {', '.join(presets)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Explore Seed Prompts\n",
    "\n",
    "Let's examine the high-quality seed prompts that will initialize our genetic algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Seed Prompt Categories:\n",
      "========================================\n",
      "\n",
      "🔹 Step By Step: 8 prompts\n",
      "   Example: \"Let's solve this step by step.\"\n",
      "   Strength: Clear sequential reasoning\n",
      "\n",
      "🔹 Visual Reasoning: 4 prompts\n",
      "   Example: \"Let me visualize this problem to better understand it.\"\n",
      "   Strength: Better spatial understanding\n",
      "\n",
      "🔹 Algebraic Approach: 5 prompts\n",
      "   Example: \"Let me define variables and set up equations for this problem.\"\n",
      "   Strength: Handles unknown quantities\n",
      "\n",
      "🔹 Logical Breakdown: 5 prompts\n",
      "   Example: \"Let me think about this logically and reason through each part.\"\n",
      "   Strength: Clear reasoning chains\n",
      "\n",
      "🔹 Pattern Recognition: 4 prompts\n",
      "   Example: \"I notice a pattern here that can help solve this more efficiently.\"\n",
      "   Strength: Efficient solutions\n",
      "\n",
      "🔹 Estimation Checking: 5 prompts\n",
      "   Example: \"Let me estimate the answer first, then calculate precisely.\"\n",
      "   Strength: Error detection through estimation\n",
      "\n",
      "🔹 Word Problem Parsing: 6 prompts\n",
      "   Example: \"Let me carefully read and understand what this problem is asking.\"\n",
      "   Strength: Better comprehension\n",
      "\n",
      "🔹 Multiple Methods: 4 prompts\n",
      "   Example: \"I can solve this in several ways - let me choose the most efficient.\"\n",
      "   Strength: Optimal approach choice\n",
      "\n",
      "🔹 Conceptual Understanding: 5 prompts\n",
      "   Example: \"Let me understand the underlying mathematical concept first.\"\n",
      "   Strength: Deep understanding\n",
      "\n",
      "🔹 Systematic Organization: 4 prompts\n",
      "   Example: \"I'll organize all the information systematically before solving.\"\n",
      "   Strength: Reduced confusion\n"
     ]
    }
   ],
   "source": [
    "# Show seed prompt categories and examples\n",
    "from src.seeds.prompt_categories import PromptCategory\n",
    "\n",
    "print(\"📂 Seed Prompt Categories:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for category in PromptCategory:\n",
    "    category_seeds = seed_manager.get_seeds_by_category(category)\n",
    "    print(f\"\\n🔹 {category.value.replace('_', ' ').title()}: {len(category_seeds)} prompts\")\n",
    "    \n",
    "    # Show first example\n",
    "    if category_seeds:\n",
    "        example = category_seeds[0]\n",
    "        print(f\"   Example: \\\"{example.text}\\\"\")\n",
    "        print(f\"   Strength: {example.expected_strength}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Seed Collection Quality Report:\n",
      "========================================\n",
      "Overall Score: 0.898\n",
      "Diversity Score: 0.771\n",
      "Category Balance: 1.000\n",
      "Uniqueness Score: 0.912\n",
      "\n",
      "Quality Status: 🟢 EXCELLENT\n"
     ]
    }
   ],
   "source": [
    "# Validate seed collection quality\n",
    "from src.seeds.seed_validation import SeedValidator\n",
    "\n",
    "validator = SeedValidator()\n",
    "validation_metrics = validator.validate_collection(base_seeds)\n",
    "\n",
    "print(\"🔍 Seed Collection Quality Report:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Overall Score: {validation_metrics.overall_score:.3f}\")\n",
    "print(f\"Diversity Score: {validation_metrics.diversity_score:.3f}\")\n",
    "print(f\"Category Balance: {validation_metrics.category_balance:.3f}\")\n",
    "print(f\"Uniqueness Score: {validation_metrics.uniqueness_score:.3f}\")\n",
    "\n",
    "quality_status = \"🟢 EXCELLENT\" if validation_metrics.overall_score >= 0.8 else \"🟡 GOOD\" if validation_metrics.overall_score >= 0.6 else \"🔴 NEEDS IMPROVEMENT\"\n",
    "print(f\"\\nQuality Status: {quality_status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Interactive Hyperparameter Configuration\n",
    "\n",
    "Use the interactive interface below to configure all genetic algorithm hyperparameters with real-time validation and visual feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚙️  Available Experiment Presets:\n",
      "==================================================\n",
      "\n",
      "🔹 quick_test\n",
      "   Name: Quick Test\n",
      "   Description: Fast test run for system validation\n",
      "   Population: 10, Generations: 15\n",
      "   Problems: 20\n",
      "\n",
      "🔹 standard\n",
      "   Name: Standard Evolution\n",
      "   Description: Standard GSM8K evolution experiment\n",
      "   Population: 50, Generations: 100\n",
      "   Problems: 100\n",
      "\n",
      "🔹 thorough\n",
      "   Name: Thorough Evolution\n",
      "   Description: Comprehensive evolution with large population\n",
      "   Population: 100, Generations: 200\n",
      "   Problems: 200\n",
      "\n",
      "🔹 ablation_no_crossover\n",
      "   Name: Ablation: No Crossover\n",
      "   Description: Evolution with mutation only (no crossover)\n",
      "   Population: 50, Generations: 100\n",
      "   Problems: 100\n",
      "\n",
      "🔹 ablation_no_mutation\n",
      "   Name: Ablation: No Mutation\n",
      "   Description: Evolution with crossover only (no mutation)\n",
      "   Population: 50, Generations: 100\n",
      "   Problems: 100\n",
      "\n",
      "🔹 high_mutation\n",
      "   Name: High Mutation Rate\n",
      "   Description: Evolution with high mutation rate\n",
      "   Population: 50, Generations: 100\n",
      "   Problems: 100\n",
      "\n",
      "🔹 large_population\n",
      "   Name: Large Population\n",
      "   Description: Evolution with large population size\n",
      "   Population: 150, Generations: 50\n",
      "   Problems: 100\n",
      "\n",
      "🔹 random_search\n",
      "   Name: Random Search Baseline\n",
      "   Description: Random search baseline for comparison\n",
      "   Population: 50, Generations: 100\n",
      "   Problems: 100\n"
     ]
    }
   ],
   "source": [
    "# Show available experiment presets\n",
    "preset_info = config_manager.get_preset_info()\n",
    "\n",
    "print(\"⚙️  Available Experiment Presets:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for name, info in preset_info.items():\n",
    "    print(f\"\\n🔹 {name}\")\n",
    "    print(f\"   Name: {info['name']}\")\n",
    "    print(f\"   Description: {info['description']}\")\n",
    "    print(f\"   Population: {info['population_size']}, Generations: {info['max_generations']}\")\n",
    "    print(f\"   Problems: {info['max_problems']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Hyperparameter Configuration Interface\n",
    "from src.config.notebook_interface import display_hyperparameter_interface, quick_config_panel\n",
    "from src.config.hyperparameters import get_hyperparameter_config\n",
    "\n",
    "print(\"🎛️ Interactive Hyperparameter Configuration Interface\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Use the interface below to configure all genetic algorithm parameters:\")\n",
    "print(\"- Adjust sliders and checkboxes to modify parameters\")\n",
    "print(\"- View parameter descriptions and valid ranges\")\n",
    "print(\"- Load presets or save custom configurations\")\n",
    "print(\"- Apply changes with real-time validation\")\n",
    "print()\n",
    "\n",
    "# Display the full interactive interface\n",
    "interface = display_hyperparameter_interface()\n",
    "display(interface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick Configuration Panel (Alternative)\n",
    "# Use this for quick adjustments to the most common parameters\n",
    "\n",
    "print(\"⚡ Quick Configuration Panel\")\n",
    "print(\"=\" * 40)\n",
    "print(\"Adjust the most commonly used parameters:\")\n",
    "print()\n",
    "\n",
    "quick_panel = quick_config_panel()\n",
    "display(quick_panel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Experiment Configuration:\n",
      "========================================\n",
      "📋 My GSM8K Evolution Experiment\n",
      "   Custom experiment for prompt evolution\n",
      "   Type: quick_test\n",
      "   Population: 50\n",
      "   Generations: 50\n",
      "   Problems: 10\n",
      "   Crossover: 80.0%\n",
      "   Mutation: 20.0%\n",
      "   Selection: tournament\n",
      "   Model: gpt-4o\n",
      "   Target Fitness: 0.95\n"
     ]
    }
   ],
   "source": [
    "# Choose and customize your experiment configuration\n",
    "# Options: 'quick_test', 'standard', 'thorough', 'high_mutation', 'large_population', etc.\n",
    "\n",
    "BASE_PRESET = \"quick_test\"  # Change this to your preferred preset\n",
    "\n",
    "# Custom modifications (optional)\n",
    "custom_modifications = {\n",
    "    'name': 'My GSM8K Evolution Experiment',\n",
    "    'description': 'Custom experiment for prompt evolution',\n",
    "    'population_size': 50,  # Adjust as needed\n",
    "    'max_generations': 50,  # Adjust as needed\n",
    "    'max_problems': 10,     # Adjust as needed (more problems = more accurate but slower)\n",
    "    'model_name': 'gpt-4o',  # or 'gpt-3.5-turbo', 'claude-3-sonnet-20240229'\n",
    "    'temperature': 0.0,     # 0.0 for deterministic, higher for more creative\n",
    "    'target_fitness': 0.95, # Stop early if this fitness is reached\n",
    "}\n",
    "\n",
    "# Create the configuration\n",
    "experiment_config = config_manager.create_custom_config(BASE_PRESET, custom_modifications)\n",
    "\n",
    "# Show the final configuration\n",
    "print(\"🔧 Experiment Configuration:\")\n",
    "print(\"=\" * 40)\n",
    "print(config_manager.get_config_summary(experiment_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show how hyperparameters are now centralized\n",
    "from src.config.hyperparameters import get_hyperparameter_config\n",
    "\n",
    "print(\"🎯 Centralized Hyperparameter Configuration\")\n",
    "print(\"=\" * 50)\n",
    "print(\"All genetic algorithm parameters are now centrally managed:\")\n",
    "print()\n",
    "\n",
    "hyperparams = get_hyperparameter_config()\n",
    "\n",
    "# Show key parameters\n",
    "print(f\"📊 Evolution Parameters:\")\n",
    "print(f\"   Population Size: {hyperparams.population_size}\")\n",
    "print(f\"   Max Generations: {hyperparams.max_generations}\")\n",
    "print(f\"   Crossover Rate: {hyperparams.crossover_rate}\")\n",
    "print(f\"   Mutation Rate: {hyperparams.mutation_rate}\")\n",
    "print(f\"   Elite Size: {hyperparams.elite_size}\")\n",
    "print(f\"   Tournament Size: {hyperparams.tournament_size}\")\n",
    "print()\n",
    "\n",
    "print(f\"🎯 Convergence Parameters:\")\n",
    "print(f\"   Target Fitness: {hyperparams.target_fitness}\")\n",
    "print(f\"   Convergence Patience: {hyperparams.convergence_patience}\")\n",
    "print(f\"   Diversity Threshold: {hyperparams.diversity_threshold}\")\n",
    "print()\n",
    "\n",
    "print(f\"🧬 Mutation Parameters:\")\n",
    "print(f\"   Semantic Probability: {hyperparams.semantic_prob}\")\n",
    "print(f\"   Insertion Rate: {hyperparams.insertion_rate}\")\n",
    "print(f\"   Deletion Rate: {hyperparams.deletion_rate}\")\n",
    "print(f\"   Max Genome Length: {hyperparams.max_genome_length}\")\n",
    "print()\n",
    "\n",
    "print(f\"📝 Evaluation Parameters:\")\n",
    "print(f\"   Max Problems: {hyperparams.max_problems}\")\n",
    "print(f\"   Batch Size: {hyperparams.batch_size}\")\n",
    "print(f\"   API Timeout: {hyperparams.api_timeout}s\")\n",
    "print(f\"   Use Cache: {hyperparams.use_cache}\")\n",
    "print()\n",
    "\n",
    "print(\"✨ Benefits of Centralized Configuration:\")\n",
    "print(\"   • All parameters in one place with validation\")\n",
    "print(\"   • Interactive notebook interface for easy modification\")\n",
    "print(\"   • Preset configurations for different experiment types\")\n",
    "print(\"   • Real-time parameter validation and error checking\")\n",
    "print(\"   • Consistent parameter usage across all modules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Configuration is valid and ready to use!\n"
     ]
    }
   ],
   "source": [
    "# Validate the configuration\n",
    "validation_errors = config_manager.validate_config(experiment_config)\n",
    "\n",
    "if validation_errors:\n",
    "    print(\"❌ Configuration validation failed:\")\n",
    "    for error in validation_errors:\n",
    "        print(f\"   - {error}\")\n",
    "else:\n",
    "    print(\"✅ Configuration is valid and ready to use!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Set Up Monitoring and Visualization\n",
    "\n",
    "Before running the experiment, let's set up real-time monitoring and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache loaded: 0 evaluation entries, 0 fitness entries\n",
      "📊 Monitoring components initialized\n",
      "✅ Ready for experiment execution\n"
     ]
    }
   ],
   "source": [
    "# Import monitoring components\n",
    "from src.utils.experiment_manager import ExperimentManager\n",
    "from src.utils.evolution_logging import EvolutionLogger\n",
    "from src.utils.visualization import EvolutionVisualizer\n",
    "from src.utils.performance_monitor import PerformanceMonitor\n",
    "\n",
    "# Initialize experiment manager\n",
    "experiment_manager = ExperimentManager()\n",
    "\n",
    "print(\"📊 Monitoring components initialized\")\n",
    "print(\"✅ Ready for experiment execution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run the Evolution Experiment\n",
    "\n",
    "Now we'll run the complete genetic algorithm experiment with real-time monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Initializing experiment runner...\n",
      "📂 Loaded collection 'test_collection' with 10 seeds\n",
      "📂 Loaded collection 'test_validation_collection' with 10 seeds\n"
     ]
    }
   ],
   "source": [
    "# Import the main experiment runner\n",
    "from src.main_runner import GSM8KExperimentRunner\n",
    "from dataclasses import asdict\n",
    "\n",
    "# Convert configuration to dictionary format\n",
    "config_dict = asdict(experiment_config)\n",
    "\n",
    "# Convert enums to strings for JSON compatibility\n",
    "for key, value in config_dict.items():\n",
    "    if hasattr(value, 'value'):\n",
    "        config_dict[key] = value.value\n",
    "\n",
    "print(\"🚀 Initializing experiment runner...\")\n",
    "runner = GSM8KExperimentRunner(config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Setting up experiment components...\n",
      "🔧 Setting up GSM8K evolution experiment...\n",
      "📚 Loading vocabulary...\n",
      "Vocabulary loaded from /Users/Odyssey/Projects/genetic-prompt/data/embeddings/vocabulary.pkl\n",
      "Vocabulary size: 10004\n",
      "   ✅ Loaded vocabulary with 10004 tokens\n",
      "📊 Loading GSM8K dataset...\n",
      "   ✅ Loaded 100 evaluation problems\n",
      "🧪 Creating experiment...\n",
      "📋 Created experiment: My GSM8K Evolution Experiment_1756385648_c29cfaf0\n",
      "   ✅ Created experiment: My GSM8K Evolution Experiment_1756385648_c29cfaf0\n",
      "📊 Initializing monitoring...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: 🧬 Starting evolution experiment: My GSM8K Evolution Experiment_1756385648_c29cfaf0\n",
      "INFO: Configuration: {\n",
      "  \"name\": \"My GSM8K Evolution Experiment\",\n",
      "  \"description\": \"Custom experiment for prompt evolution\",\n",
      "  \"experiment_type\": \"quick_test\",\n",
      "  \"population_size\": 50,\n",
      "  \"max_generations\": 50,\n",
      "  \"crossover_rate\": 0.8,\n",
      "  \"mutation_rate\": 0.2,\n",
      "  \"elite_size\": 5,\n",
      "  \"selection_method\": \"tournament\",\n",
      "  \"tournament_size\": 3,\n",
      "  \"crossover_type\": \"single_point\",\n",
      "  \"mutation_type\": \"semantic\",\n",
      "  \"target_fitness\": 0.95,\n",
      "  \"convergence_patience\": 5,\n",
      "  \"adaptive_parameters\": true,\n",
      "  \"max_problems\": 10,\n",
      "  \"use_cache\": true,\n",
      "  \"batch_size\": 10,\n",
      "  \"seed_strategy\": \"balanced\",\n",
      "  \"custom_seeds\": null,\n",
      "  \"save_checkpoints\": true,\n",
      "  \"checkpoint_interval\": 5,\n",
      "  \"enable_visualization\": true,\n",
      "  \"performance_monitoring\": true,\n",
      "  \"model_name\": \"gpt-4o\",\n",
      "  \"temperature\": 0.0,\n",
      "  \"max_tokens\": 150,\n",
      "  \"save_results\": true,\n",
      "  \"save_plots\": true,\n",
      "  \"verbose\": true\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Started experiment: My GSM8K Evolution Experiment_1756385648_c29cfaf0\n",
      "📊 Performance monitor initialized for experiment: My GSM8K Evolution Experiment_1756385648_c29cfaf0\n",
      "   ✅ Monitoring initialized\n",
      "⚡ Setting up evaluation pipeline...\n",
      "   ✅ Evaluation pipeline ready (Model: gpt-4o)\n",
      "🌱 Loading seed prompts...\n",
      "   ✅ Loaded 50 seed prompts\n",
      "🧬 Initializing evolution controller...\n",
      "   ✅ Evolution controller ready\n",
      "✅ Experiment setup completed successfully!\n",
      "✅ Experiment setup completed successfully!\n",
      "📋 Experiment ID: My GSM8K Evolution Experiment_1756385648_c29cfaf0\n"
     ]
    }
   ],
   "source": [
    "# Set up the experiment\n",
    "print(\"🔧 Setting up experiment components...\")\n",
    "setup_success = runner.setup_experiment()\n",
    "\n",
    "if setup_success:\n",
    "    print(\"✅ Experiment setup completed successfully!\")\n",
    "    print(f\"📋 Experiment ID: {runner.experiment_id}\")\n",
    "else:\n",
    "    print(\"❌ Experiment setup failed. Please check the error messages above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧬 Starting genetic algorithm evolution...\n",
      "============================================================\n",
      "Population Size: 50\n",
      "Max Generations: 50\n",
      "Evaluation Problems: 10\n",
      "Model: gpt-4o\n",
      "============================================================\n",
      "\n",
      "🚀 Starting GSM8K evolution experiment: My GSM8K Evolution Experiment_1756385648_c29cfaf0\n",
      "============================================================\n",
      "🧬 Starting evolution with 50 genomes\n",
      "Target fitness: 0.95\n",
      "Max generations: 50\n",
      "Initialized population with 50 seeds and 0 random genomes\n",
      "Initialized population with 50 seed prompts\n",
      "Generation 0: Evaluating on 50 problems\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating population (fitness: 0.350): 100%|██████████| 50/50 [28:40<00:00, 34.41s/it, genome=seed_49, problem=10/10, correct=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1: best=-inf, mean=0.328, diversity=0.895\n",
      "Generation 1: Evaluating on 50 problems\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating population (fitness: 0.490): 100%|██████████| 50/50 [26:56<00:00, 32.32s/it, genome=51413e74, problem=10/10, correct=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 2: best=-inf, mean=0.504, diversity=0.891\n",
      "Generation 2: Evaluating on 50 problems\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating population (fitness: 0.345):  70%|███████   | 35/50 [19:39<08:16, 33.10s/it, genome=a89d2b35, problem=2/10, correct=0] "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# This will run the complete evolution process\u001b[39;00m\n\u001b[32m     12\u001b[39m start_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m experiment_success = \u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m total_time = time.time() - start_time\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m⏱️  Total experiment time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/genetic-prompt/src/main_runner.py:203\u001b[39m, in \u001b[36mGSM8KExperimentRunner.run_experiment\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;66;03m# Run evolution\u001b[39;00m\n\u001b[32m    202\u001b[39m start_time = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m \u001b[38;5;28mself\u001b[39m.final_results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevolution_controller\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_evolution\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m total_time = time.time() - start_time\n\u001b[32m    206\u001b[39m \u001b[38;5;66;03m# Extract best prompt\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/genetic-prompt/src/genetics/evolution.py:303\u001b[39m, in \u001b[36mEvolutionController.run_evolution\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    301\u001b[39m \u001b[38;5;66;03m# Evolution loop\u001b[39;00m\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m303\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevolve_generation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    305\u001b[39m     \u001b[38;5;66;03m# Print progress\u001b[39;00m\n\u001b[32m    306\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGeneration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult.generation\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    307\u001b[39m           \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbest=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult.best_fitness\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    308\u001b[39m           \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmean=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult.mean_fitness\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    309\u001b[39m           \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdiversity=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult.diversity\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/genetic-prompt/src/genetics/evolution.py:165\u001b[39m, in \u001b[36mEvolutionController.evolve_generation\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    163\u001b[39m \u001b[38;5;66;03m# Evaluate population\u001b[39;00m\n\u001b[32m    164\u001b[39m eval_start = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m evaluation_results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluation_pipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate_adaptive\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpopulation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpopulation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgeneration\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m eval_time = time.time() - eval_start\n\u001b[32m    170\u001b[39m \u001b[38;5;28mself\u001b[39m.total_evaluations += \u001b[38;5;28mlen\u001b[39m(evaluation_results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/genetic-prompt/src/evaluation/pipeline.py:243\u001b[39m, in \u001b[36mEvaluationPipeline.evaluate_adaptive\u001b[39m\u001b[34m(self, population, generation)\u001b[39m\n\u001b[32m    239\u001b[39m problems = gsm8k_dataset.get_adaptive_eval_problems(generation)\n\u001b[32m    241\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGeneration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgeneration\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: Evaluating on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(problems)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m problems\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluate_population\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpopulation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproblems\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/genetic-prompt/src/evaluation/pipeline.py:196\u001b[39m, in \u001b[36mEvaluationPipeline.evaluate_population\u001b[39m\u001b[34m(self, population, problems, progress_callback)\u001b[39m\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, genome \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(population):\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluate_genome\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenome\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproblems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_progress\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    197\u001b[39m         results.append(result)\n\u001b[32m    199\u001b[39m         \u001b[38;5;66;03m# Update genome fitness\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/genetic-prompt/src/evaluation/pipeline.py:133\u001b[39m, in \u001b[36mEvaluationPipeline.evaluate_genome\u001b[39m\u001b[34m(self, genome, problems, progress_callback)\u001b[39m\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m progress_callback:\n\u001b[32m    131\u001b[39m         progress_callback(genome.genome_id, current, total, result)\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m evaluation_results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm_interface\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_problems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_wrapper\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[38;5;66;03m# Calculate fitness\u001b[39;00m\n\u001b[32m    138\u001b[39m fitness_components = \u001b[38;5;28mself\u001b[39m.fitness_calculator.calculate_fitness(\n\u001b[32m    139\u001b[39m     genome, evaluation_results\n\u001b[32m    140\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/genetic-prompt/src/evaluation/llm_interface.py:177\u001b[39m, in \u001b[36mLLMInterface.batch_evaluate\u001b[39m\u001b[34m(self, prompt, problems, progress_callback)\u001b[39m\n\u001b[32m    174\u001b[39m ground_truth = problem[\u001b[33m'\u001b[39m\u001b[33mfinal_answer\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    176\u001b[39m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m predicted_answer, response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluate_prompt_on_problem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[38;5;66;03m# Calculate correctness\u001b[39;00m\n\u001b[32m    180\u001b[39m is_correct = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/genetic-prompt/src/evaluation/llm_interface.py:140\u001b[39m, in \u001b[36mLLMInterface.evaluate_prompt_on_problem\u001b[39m\u001b[34m(self, prompt, question)\u001b[39m\n\u001b[32m    135\u001b[39m messages = [\n\u001b[32m    136\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: full_prompt}\n\u001b[32m    137\u001b[39m ]\n\u001b[32m    139\u001b[39m \u001b[38;5;66;03m# Make API request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_api_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/genetic-prompt/src/evaluation/llm_interface.py:79\u001b[39m, in \u001b[36mLLMInterface._make_api_request\u001b[39m\u001b[34m(self, messages)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.max_retries):\n\u001b[32m     78\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m         response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\n\u001b[32m     85\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m         \u001b[38;5;66;03m# Update statistics\u001b[39;00m\n\u001b[32m     88\u001b[39m         \u001b[38;5;28mself\u001b[39m.total_requests += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/genetic-prompt/gsm8k_ga_env/lib/python3.13/site-packages/openai/_utils/_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/genetic-prompt/gsm8k_ga_env/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py:1147\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1101\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1103\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1144\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m   1145\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1146\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1156\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1181\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1188\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1189\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1191\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1192\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/genetic-prompt/gsm8k_ga_env/lib/python3.13/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/genetic-prompt/gsm8k_ga_env/lib/python3.13/site-packages/openai/_base_client.py:982\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    980\u001b[39m response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    981\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m982\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    987\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    988\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/genetic-prompt/gsm8k_ga_env/lib/python3.13/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/genetic-prompt/gsm8k_ga_env/lib/python3.13/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/genetic-prompt/gsm8k_ga_env/lib/python3.13/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/genetic-prompt/gsm8k_ga_env/lib/python3.13/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/genetic-prompt/gsm8k_ga_env/lib/python3.13/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/genetic-prompt/gsm8k_ga_env/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/genetic-prompt/gsm8k_ga_env/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/genetic-prompt/gsm8k_ga_env/lib/python3.13/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/genetic-prompt/gsm8k_ga_env/lib/python3.13/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/genetic-prompt/gsm8k_ga_env/lib/python3.13/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/genetic-prompt/gsm8k_ga_env/lib/python3.13/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/genetic-prompt/gsm8k_ga_env/lib/python3.13/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/genetic-prompt/gsm8k_ga_env/lib/python3.13/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/Cellar/python@3.13/3.13.0_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1285\u001b[39m, in \u001b[36mSSLSocket.recv\u001b[39m\u001b[34m(self, buflen, flags)\u001b[39m\n\u001b[32m   1281\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1282\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1283\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1284\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1286\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1287\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv(buflen, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/Cellar/python@3.13/3.13.0_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1140\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1141\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[32m   1142\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.args[\u001b[32m0\u001b[39m] == SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.suppress_ragged_eofs:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Run the evolution experiment\n",
    "if setup_success:\n",
    "    print(\"🧬 Starting genetic algorithm evolution...\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Population Size: {experiment_config.population_size}\")\n",
    "    print(f\"Max Generations: {experiment_config.max_generations}\")\n",
    "    print(f\"Evaluation Problems: {experiment_config.max_problems}\")\n",
    "    print(f\"Model: {experiment_config.model_name}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # This will run the complete evolution process\n",
    "    start_time = time.time()\n",
    "    experiment_success = runner.run_experiment()\n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n⏱️  Total experiment time: {total_time:.1f} seconds\")\n",
    "    \n",
    "    if experiment_success:\n",
    "        print(\"🎉 Experiment completed successfully!\")\n",
    "    else:\n",
    "        print(\"❌ Experiment failed. Check the logs for details.\")\n",
    "else:\n",
    "    print(\"⚠️  Skipping experiment run due to setup failure.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the results analyzer\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the scripts directory to path\n",
    "scripts_dir = Path.cwd() / \"scripts\"\n",
    "if str(scripts_dir) not in sys.path:\n",
    "    sys.path.append(str(scripts_dir))\n",
    "\n",
    "from notebook_results_analyzer import analyze_results\n",
    "\n",
    "# Analyze the existing experiment results\n",
    "results = analyze_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Analyze Results\n",
    "\n",
    "Let's examine the results of our evolution experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get experiment summary\n",
    "if 'experiment_success' in locals() and experiment_success:\n",
    "    summary = runner.get_experiment_summary()\n",
    "    \n",
    "    print(\"📊 Experiment Results Summary:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Status: {summary['status']}\")\n",
    "    print(f\"Experiment ID: {summary['experiment_id']}\")\n",
    "    \n",
    "    if 'results' in summary:\n",
    "        results = summary['results']\n",
    "        print(f\"\\n🏆 Evolution Results:\")\n",
    "        print(f\"   Best Fitness: {results.get('best_fitness', 0):.3f}\")\n",
    "        print(f\"   Total Generations: {results.get('total_generations', 0)}\")\n",
    "        print(f\"   Convergence Reason: {results.get('convergence_reason', 'unknown')}\")\n",
    "        print(f\"   Total Evaluations: {results.get('total_evaluations', 0)}\")\n",
    "        \n",
    "        if summary.get('best_prompt'):\n",
    "            print(f\"\\n🎯 Best Evolved Prompt:\")\n",
    "            print(f'   \"{summary[\"best_prompt\"]}\"')\n",
    "else:\n",
    "    print(\"⚠️  No results to analyze - experiment was not run or failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show performance statistics\n",
    "if 'summary' in locals() and 'performance' in summary:\n",
    "    perf = summary['performance']\n",
    "    \n",
    "    print(\"⚡ Performance Statistics:\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Runtime: {perf.get('total_runtime_minutes', 0):.1f} minutes\")\n",
    "    \n",
    "    if 'api_usage' in perf:\n",
    "        api = perf['api_usage']\n",
    "        print(f\"\\n🔌 API Usage:\")\n",
    "        print(f\"   Total API Calls: {api.get('total_calls', 0)}\")\n",
    "        print(f\"   Total Tokens: {api.get('total_tokens', 0):,}\")\n",
    "        print(f\"   Tokens per Call: {api.get('tokens_per_call', 0):.1f}\")\n",
    "    \n",
    "    if 'cache_performance' in perf:\n",
    "        cache = perf['cache_performance']\n",
    "        print(f\"\\n💾 Cache Performance:\")\n",
    "        print(f\"   Hit Rate: {cache.get('hit_rate', 0):.1%}\")\n",
    "        print(f\"   Total Hits: {cache.get('total_hits', 0)}\")\n",
    "        print(f\"   Total Misses: {cache.get('total_misses', 0)}\")\n",
    "    \n",
    "    if 'memory_usage' in perf:\n",
    "        memory = perf['memory_usage']\n",
    "        print(f\"\\n🧠 Memory Usage:\")\n",
    "        print(f\"   Peak Memory: {memory.get('peak_mb', 0):.1f} MB\")\n",
    "        print(f\"   Memory Growth: {memory.get('growth_mb', 0):.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualize Evolution Progress\n",
    "\n",
    "Let's look at the evolution progress through visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display evolution plots if available\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display\n",
    "\n",
    "if 'runner' in locals() and runner.experiment_id:\n",
    "    # Look for generated plots\n",
    "    plots_dir = config.get_data_dir() / \"plots\" / runner.experiment_id\n",
    "    \n",
    "    if plots_dir.exists():\n",
    "        print(\"📈 Evolution Visualizations:\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        # Show final evolution progress plot\n",
    "        final_plot = plots_dir / \"final_evolution_progress.png\"\n",
    "        if final_plot.exists():\n",
    "            print(\"\\n🔹 Evolution Progress:\")\n",
    "            display(Image(str(final_plot)))\n",
    "        \n",
    "        # Show convergence analysis\n",
    "        convergence_plot = plots_dir / \"convergence_analysis.png\"\n",
    "        if convergence_plot.exists():\n",
    "            print(\"\\n🔹 Convergence Analysis:\")\n",
    "            display(Image(str(convergence_plot)))\n",
    "        \n",
    "        # List all available plots\n",
    "        all_plots = list(plots_dir.glob(\"*.png\"))\n",
    "        print(f\"\\n📊 Total plots generated: {len(all_plots)}\")\n",
    "        for plot in all_plots:\n",
    "            print(f\"   - {plot.name}\")\n",
    "    else:\n",
    "        print(\"⚠️  No visualization plots found.\")\n",
    "else:\n",
    "    print(\"⚠️  No experiment data available for visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Compare with Baseline Prompts\n",
    "\n",
    "Let's compare our evolved prompt with some baseline prompts to see the improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define baseline prompts for comparison\n",
    "baseline_prompts = [\n",
    "    \"Solve this math problem.\",\n",
    "    \"Let's solve this step by step.\",\n",
    "    \"Think carefully and solve this problem.\",\n",
    "    \"Calculate the answer to this question.\"\n",
    "]\n",
    "\n",
    "print(\"📋 Baseline Prompts for Comparison:\")\n",
    "print(\"=\" * 40)\n",
    "for i, prompt in enumerate(baseline_prompts, 1):\n",
    "    print(f\"{i}. \\\"{prompt}\\\"\")\n",
    "\n",
    "if 'summary' in locals() and summary.get('best_prompt'):\n",
    "    print(f\"\\n🧬 Evolved Prompt:\")\n",
    "    print(f'   \"{summary[\"best_prompt\"]}\"')\n",
    "    \n",
    "    print(f\"\\n🎯 Best Fitness Achieved: {summary.get('results', {}).get('best_fitness', 0):.3f}\")\n",
    "    print(\"\\n💡 The evolved prompt should show improvements in:\")\n",
    "    print(\"   - Mathematical reasoning clarity\")\n",
    "    print(\"   - Step-by-step problem solving\")\n",
    "    print(\"   - Accuracy on GSM8K problems\")\n",
    "else:\n",
    "    print(\"\\n⚠️  No evolved prompt available for comparison.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Advanced: Custom Experiment Configurations\n",
    "\n",
    "Here are examples of how to set up different types of experiments for research purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Ablation Study - No Crossover\n",
    "ablation_config = config_manager.create_custom_config('standard', {\n",
    "    'name': 'Ablation Study: Mutation Only',\n",
    "    'crossover_rate': 0.0,\n",
    "    'mutation_rate': 0.5,\n",
    "    'max_generations': 50\n",
    "})\n",
    "\n",
    "print(\"🔬 Ablation Study Configuration:\")\n",
    "print(config_manager.get_config_summary(ablation_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Parameter Sweep - Different Model Comparison\n",
    "model_configs = {\n",
    "    'gpt-4o': {'model_name': 'gpt-4o', 'temperature': 0.0},\n",
    "    'gpt-4o-creative': {'model_name': 'gpt-4o', 'temperature': 0.3},\n",
    "    'gpt-3.5-turbo': {'model_name': 'gpt-3.5-turbo', 'temperature': 0.0}\n",
    "}\n",
    "\n",
    "print(\"🔄 Model Comparison Configurations:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for name, modifications in model_configs.items():\n",
    "    config = config_manager.create_custom_config('quick_test', {\n",
    "        'name': f'Model Comparison: {name}',\n",
    "        **modifications\n",
    "    })\n",
    "    print(f\"\\n🔹 {name}:\")\n",
    "    print(f\"   Model: {config.model_name}\")\n",
    "    print(f\"   Temperature: {config.temperature}\")\n",
    "    print(f\"   Population: {config.population_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Custom Seed Prompts\n",
    "custom_seeds = [\n",
    "    \"Let me approach this systematically by breaking down the problem.\",\n",
    "    \"I'll solve this by identifying the key information and working step by step.\",\n",
    "    \"To find the answer, I need to carefully analyze what's given and what's asked.\"\n",
    "]\n",
    "\n",
    "custom_seed_config = config_manager.create_custom_config('quick_test', {\n",
    "    'name': 'Custom Seed Experiment',\n",
    "    'custom_seeds': custom_seeds,\n",
    "    'population_size': len(custom_seeds) * 3  # Expand from custom seeds\n",
    "})\n",
    "\n",
    "print(\"🌱 Custom Seed Configuration:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Custom Seeds: {len(custom_seeds)}\")\n",
    "print(f\"Population Size: {custom_seed_config.population_size}\")\n",
    "print(\"\\nCustom Seed Prompts:\")\n",
    "for i, seed in enumerate(custom_seeds, 1):\n",
    "    print(f\"   {i}. \\\"{seed}\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Experiment Management and History\n",
    "\n",
    "Learn how to manage multiple experiments and track your research progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all experiments\n",
    "all_experiments = experiment_manager.list_experiments()\n",
    "\n",
    "print(\"📚 Experiment History:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if all_experiments:\n",
    "    for exp in all_experiments[:5]:  # Show last 5 experiments\n",
    "        print(f\"\\n🔹 {exp.experiment_name}\")\n",
    "        print(f\"   ID: {exp.experiment_id}\")\n",
    "        print(f\"   Status: {exp.status}\")\n",
    "        print(f\"   Created: {time.ctime(exp.created_at)}\")\n",
    "        if exp.status == 'completed':\n",
    "            print(f\"   Best Fitness: {exp.best_fitness:.3f}\")\n",
    "            print(f\"   Generations: {exp.total_generations}\")\n",
    "            print(f\"   Runtime: {exp.total_time:.1f}s\")\n",
    "else:\n",
    "    print(\"No experiments found in history.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get experiment summary statistics\n",
    "summary_stats = experiment_manager.get_experiment_summary()\n",
    "\n",
    "print(\"📊 Overall Experiment Statistics:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Total Experiments: {summary_stats['total_experiments']}\")\n",
    "print(f\"Completed: {summary_stats['status_counts'].get('completed', 0)}\")\n",
    "print(f\"Running: {summary_stats['status_counts'].get('running', 0)}\")\n",
    "print(f\"Failed: {summary_stats['status_counts'].get('failed', 0)}\")\n",
    "\n",
    "if summary_stats['completed_experiments'] > 0:\n",
    "    print(f\"\\n📈 Averages (Completed Experiments):\")\n",
    "    print(f\"   Average Best Fitness: {summary_stats['average_best_fitness']:.3f}\")\n",
    "    print(f\"   Average Generations: {summary_stats['average_generations']:.1f}\")\n",
    "    print(f\"   Average Runtime: {summary_stats['average_time']:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Tips and Best Practices\n",
    "\n",
    "Here are some recommendations for getting the best results from your experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎯 **Experiment Design Tips:**\n",
    "\n",
    "1. **Start Small**: Use `quick_test` preset first to validate your setup\n",
    "2. **Problem Count**: More evaluation problems = more accurate fitness but slower evolution\n",
    "3. **Population Size**: Larger populations explore more but cost more API calls\n",
    "4. **Generations**: Allow enough generations for convergence (typically 50-100)\n",
    "\n",
    "### ⚙️ **Parameter Tuning:**\n",
    "\n",
    "- **High Exploration**: Increase mutation rate (0.3-0.5) and population size\n",
    "- **High Exploitation**: Increase crossover rate (0.8-0.9) and elite size\n",
    "- **Balanced**: Use default parameters from `standard` preset\n",
    "\n",
    "### 💰 **Cost Management:**\n",
    "\n",
    "- Enable caching (`use_cache=True`) to avoid re-evaluating identical prompts\n",
    "- GPT-4o provides best performance (use `gpt-3.5-turbo` for cost efficiency)\n",
    "- Use smaller problem sets for initial experiments\n",
    "\n",
    "### 📊 **Result Interpretation:**\n",
    "\n",
    "- Fitness > 0.8 indicates strong mathematical reasoning\n",
    "- Look for convergence patterns in the evolution plots\n",
    "- Compare evolved prompts with baseline prompts on held-out test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Cleanup and Next Steps\n",
    "\n",
    "Clean up resources and explore further research directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup experiment resources\n",
    "if 'runner' in locals():\n",
    "    runner.cleanup()\n",
    "    print(\"🧹 Experiment resources cleaned up\")\n",
    "\n",
    "print(\"\\n🎉 Tutorial completed successfully!\")\n",
    "print(\"\\n🚀 Next Steps:\")\n",
    "print(\"   1. Try different experiment presets\")\n",
    "print(\"   2. Experiment with custom seed prompts\")\n",
    "print(\"   3. Compare different models (GPT-4o, GPT-3.5-turbo, Claude)\")\n",
    "print(\"   4. Run ablation studies to understand component contributions\")\n",
    "print(\"   5. Evaluate evolved prompts on additional math datasets\")\n",
    "\n",
    "print(\"\\n📚 For more advanced usage, see:\")\n",
    "print(\"   - scripts/run_experiment.py for command-line usage\")\n",
    "print(\"   - src/config/experiment_configs.py for configuration options\")\n",
    "print(\"   - Generated plots and logs in the data/ directory\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsm8k_ga_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
