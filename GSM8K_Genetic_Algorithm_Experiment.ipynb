{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GSM8K Genetic Algorithm Experiment\n",
    "\n",
    "This notebook orchestrates genetic algorithm experiments for evolving optimal prompts for GSM8K math problems.\n",
    "\n",
    "**Target**: Achieve 95% accuracy through evolutionary optimization of 500-member populations across 30 generations.\n",
    "\n",
    "## System Overview\n",
    "- **Population Size**: 500 genomes\n",
    "- **Generations**: Up to 30\n",
    "- **Model**: GPT-4o\n",
    "- **Selection**: Elite (20) + Diverse (1) + Random (1)\n",
    "- **Mutation**: Semantic neighborhoods with 2-level probability\n",
    "- **Evaluation**: Progressive (50/100/150 problems per generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import asyncio\n",
    "import logging\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('./src')\n",
    "\n",
    "# Import our genetic algorithm components\n",
    "from src.genetics.evolution_controller import EvolutionController\n",
    "from src.genetics.generation_manager import GenerationManager\n",
    "from src.utils.config import get_config\n",
    "from src.utils.dataset import GSM8KDataset\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"üß¨ GSM8K Genetic Algorithm System Initialized\")\n",
    "print(f\"üìÖ Experiment Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Configuration and Display Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config = get_config()\n",
    "\n",
    "# Display current configuration\n",
    "print(\"‚öôÔ∏è Current Configuration:\")\n",
    "print(f\"  Model: {config.get('model.name')}\")\n",
    "print(f\"  Population Size: {config.get('genetic_algorithm.population_size')}\")\n",
    "print(f\"  Max Generations: {config.get('genetic_algorithm.max_generations')}\")\n",
    "print(f\"  Target Accuracy: {config.get('experiment.target_accuracy'):.1%}\")\n",
    "print(f\"  Elite Selection: {config.get('selection.elite_count')}\")\n",
    "print(f\"  Diverse Selection: {config.get('selection.diverse_count')}\")\n",
    "print(f\"  Random Selection: {config.get('selection.random_count')}\")\n",
    "print(f\"  Mutation Rate (Population): {config.get('mutation.population_mutation_prob'):.1%}\")\n",
    "print(f\"  Mutation Rate (Token): {config.get('mutation.token_mutation_prob'):.3%}\")\n",
    "print(f\"  Semantic Neighbor Prob: {config.get('mutation.semantic_neighbor_prob'):.1%}\")\n",
    "\n",
    "# Progressive evaluation settings\n",
    "eval_config = config.get('evaluation.progressive_evaluation')\n",
    "print(f\"\\nüìä Progressive Evaluation:\")\n",
    "print(f\"  Early Generations (1-10): {eval_config['early_generations']['problems_per_genome']} problems\")\n",
    "print(f\"  Middle Generations (11-20): {eval_config['middle_generations']['problems_per_genome']} problems\")\n",
    "print(f\"  Late Generations (21-30): {eval_config['late_generations']['problems_per_genome']} problems\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize System Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize main components\n",
    "print(\"üîß Initializing system components...\")\n",
    "\n",
    "evolution_controller = EvolutionController()\n",
    "generation_manager = GenerationManager()\n",
    "dataset = GSM8KDataset()\n",
    "\n",
    "print(\"‚úÖ Evolution Controller initialized\")\n",
    "print(\"‚úÖ Generation Manager initialized\")\n",
    "print(\"‚úÖ Dataset Manager initialized\")\n",
    "\n",
    "# Verify dataset is ready\n",
    "try:\n",
    "    train_data, test_data = dataset.load_dataset()\n",
    "    print(f\"üìö Dataset loaded: {len(train_data)} training, {len(test_data)} test problems\")\n",
    "    \n",
    "    # Load evaluation sets\n",
    "    eval_sets = dataset.create_evaluation_sets()\n",
    "    for set_name, set_data in eval_sets.items():\n",
    "        print(f\"  {set_name}: {len(set_data)} problems\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Dataset error: {e}\")\n",
    "    print(\"Please run: python scripts/prepare_dataset.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Seed Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define diverse seed prompts for different problem-solving strategies\n",
    "SEED_PROMPTS = [\n",
    "    \"Solve this step by step.\",\n",
    "    \"Let's work through this problem carefully.\",\n",
    "    \"First, identify what we need to find.\",\n",
    "    \"Break down the problem into smaller parts.\",\n",
    "    \"Calculate each step systematically.\",\n",
    "    \"Let me solve this math problem step by step.\",\n",
    "    \"To find the answer, I need to:\",\n",
    "    \"Let's start by understanding what the problem is asking.\",\n",
    "    \"I'll solve this by working through each part.\",\n",
    "    \"Here's how to approach this problem:\",\n",
    "    \"Step 1: Read the problem carefully.\",\n",
    "    \"Let's organize the given information.\",\n",
    "    \"I need to find the total by adding up all parts.\",\n",
    "    \"To solve this, I'll use basic arithmetic.\",\n",
    "    \"Let me calculate this step by step.\",\n",
    "    \"First, let's identify the key numbers.\",\n",
    "    \"I'll work through this systematically.\",\n",
    "    \"Let's solve this math problem together.\",\n",
    "    \"To get the answer, I need to calculate:\",\n",
    "    \"Here's my step-by-step solution:\",\n",
    "    \"Let me break this down into simple steps.\",\n",
    "    \"I'll solve this using logical reasoning.\",\n",
    "    \"First, I'll find what we know.\",\n",
    "    \"Let's calculate the answer step by step.\",\n",
    "    \"To solve this problem, I will:\",\n",
    "    \"Let me work through this calculation.\",\n",
    "    \"I need to find the solution by:\",\n",
    "    \"Here's how I'll approach this:\",\n",
    "    \"Let's solve this math word problem.\",\n",
    "    \"I'll calculate the answer systematically.\",\n",
    "    \"First, let me understand the problem.\",\n",
    "    \"To find the solution, I'll:\",\n",
    "    \"Let me solve this problem carefully.\",\n",
    "    \"I'll work through each calculation.\",\n",
    "    \"Here's my mathematical approach:\",\n",
    "    \"Let's find the answer step by step.\",\n",
    "    \"I need to calculate the total amount.\",\n",
    "    \"To solve this, I'll use math operations.\",\n",
    "    \"Let me figure out the answer.\",\n",
    "    \"I'll solve this problem methodically.\",\n",
    "    \"First, I'll identify the operation needed.\",\n",
    "    \"Let's work out the solution together.\",\n",
    "    \"I need to find the correct answer by:\",\n",
    "    \"Here's how to solve this math problem:\",\n",
    "    \"Let me calculate the final result.\",\n",
    "    \"I'll solve this using arithmetic.\",\n",
    "    \"To get the right answer, I'll:\",\n",
    "    \"Let me work through this step by step.\",\n",
    "    \"I need to solve for the unknown value.\",\n",
    "    \"Here's my solution to this problem:\"\n",
    "]\n",
    "\n",
    "print(f\"üå± Defined {len(SEED_PROMPTS)} diverse seed prompts\")\n",
    "print(\"\\nSample seed prompts:\")\n",
    "for i, prompt in enumerate(SEED_PROMPTS[:5]):\n",
    "    print(f\"  {i+1}. {prompt}\")\n",
    "print(f\"  ... and {len(SEED_PROMPTS)-5} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Experiment Control Panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment configuration\n",
    "EXPERIMENT_CONFIG = {\n",
    "    'experiment_name': f\"GSM8K_GA_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n",
    "    'population_size': config.get('genetic_algorithm.population_size'),\n",
    "    'max_generations': config.get('genetic_algorithm.max_generations'),\n",
    "    'use_full_config': True,  # Set to False for quick testing\n",
    "    'save_checkpoints': True,\n",
    "    'show_progress': True\n",
    "}\n",
    "\n",
    "# For quick testing, override with smaller values\n",
    "if not EXPERIMENT_CONFIG['use_full_config']:\n",
    "    EXPERIMENT_CONFIG.update({\n",
    "        'population_size': 20,\n",
    "        'max_generations': 5\n",
    "    })\n",
    "    evolution_controller.population_size = 20\n",
    "    evolution_controller.max_generations = 5\n",
    "    print(\"‚ö†Ô∏è Using QUICK TEST configuration (20 population, 5 generations)\")\n",
    "else:\n",
    "    print(\"üöÄ Using FULL SCALE configuration\")\n",
    "\n",
    "print(f\"\\nüß™ Experiment Configuration:\")\n",
    "for key, value in EXPERIMENT_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evolution Progress Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables for tracking progress\n",
    "evolution_metrics = {\n",
    "    'generations': [],\n",
    "    'best_fitness': [],\n",
    "    'best_accuracy': [],\n",
    "    'mean_fitness': [],\n",
    "    'population_diversity': [],\n",
    "    'evaluation_times': [],\n",
    "    'total_cost': 0.0,\n",
    "    'start_time': None,\n",
    "    'current_best_genome': None\n",
    "}\n",
    "\n",
    "def update_metrics(generation_stats, population):\n",
    "    \"\"\"Update evolution metrics with new generation data.\"\"\"\n",
    "    gen = generation_stats['generation']\n",
    "    \n",
    "    evolution_metrics['generations'].append(gen)\n",
    "    evolution_metrics['best_fitness'].append(generation_stats['best_fitness'])\n",
    "    evolution_metrics['best_accuracy'].append(generation_stats['best_accuracy'])\n",
    "    evolution_metrics['evaluation_times'].append(generation_stats.get('generation_time_seconds', 0))\n",
    "    \n",
    "    # Calculate mean fitness\n",
    "    evaluated_genomes = [g for g in population if g.fitness is not None]\n",
    "    if evaluated_genomes:\n",
    "        mean_fit = sum(g.fitness for g in evaluated_genomes) / len(evaluated_genomes)\n",
    "        evolution_metrics['mean_fitness'].append(mean_fit)\n",
    "        \n",
    "        # Calculate diversity (fitness standard deviation)\n",
    "        fitnesses = [g.fitness for g in evaluated_genomes]\n",
    "        if len(fitnesses) > 1:\n",
    "            mean_fitness = sum(fitnesses) / len(fitnesses)\n",
    "            variance = sum((f - mean_fitness) ** 2 for f in fitnesses) / len(fitnesses)\n",
    "            diversity = variance ** 0.5\n",
    "        else:\n",
    "            diversity = 0.0\n",
    "        evolution_metrics['population_diversity'].append(diversity)\n",
    "        \n",
    "        # Track best genome\n",
    "        best_genome = max(evaluated_genomes, key=lambda g: g.fitness)\n",
    "        evolution_metrics['current_best_genome'] = {\n",
    "            'generation': gen,\n",
    "            'fitness': best_genome.fitness,\n",
    "            'accuracy': best_genome.accuracy,\n",
    "            'text': best_genome.to_text(),\n",
    "            'length': len(best_genome.tokens)\n",
    "        }\n",
    "\n",
    "def display_progress():\n",
    "    \"\"\"Display current evolution progress.\"\"\"\n",
    "    if not evolution_metrics['generations']:\n",
    "        print(\"No evolution data yet.\")\n",
    "        return\n",
    "    \n",
    "    current_gen = evolution_metrics['generations'][-1]\n",
    "    best_fitness = evolution_metrics['best_fitness'][-1]\n",
    "    best_accuracy = evolution_metrics['best_accuracy'][-1]\n",
    "    mean_fitness = evolution_metrics['mean_fitness'][-1] if evolution_metrics['mean_fitness'] else 0\n",
    "    \n",
    "    elapsed_time = time.time() - evolution_metrics['start_time'] if evolution_metrics['start_time'] else 0\n",
    "    \n",
    "    print(f\"\\nüìä Generation {current_gen} Progress:\")\n",
    "    print(f\"  Best Fitness: {best_fitness:.4f}\")\n",
    "    print(f\"  Best Accuracy: {best_accuracy:.1%}\")\n",
    "    print(f\"  Mean Fitness: {mean_fitness:.4f}\")\n",
    "    print(f\"  Elapsed Time: {elapsed_time/60:.1f} minutes\")\n",
    "    \n",
    "    if evolution_metrics['current_best_genome']:\n",
    "        best = evolution_metrics['current_best_genome']\n",
    "        print(f\"  Best Genome: '{best['text']}' (length: {best['length']})\")\n",
    "    \n",
    "    # Progress toward target\n",
    "    target_accuracy = config.get('experiment.target_accuracy', 0.95)\n",
    "    progress = best_accuracy / target_accuracy\n",
    "    print(f\"  Progress to Target: {progress:.1%} (target: {target_accuracy:.1%})\")\n",
    "\n",
    "print(\"üìà Evolution tracking system initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run Evolution Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_evolution_experiment():\n",
    "    \"\"\"Run the complete evolution experiment.\"\"\"\n",
    "    \n",
    "    # Start experiment\n",
    "    experiment_id = generation_manager.start_experiment(EXPERIMENT_CONFIG['experiment_name'])\n",
    "    evolution_metrics['start_time'] = time.time()\n",
    "    \n",
    "    print(f\"üöÄ Starting Evolution Experiment: {experiment_id}\")\n",
    "    print(f\"üìÖ Start Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    # Define progress callback\n",
    "    def progress_callback(generation_stats):\n",
    "        # Update metrics\n",
    "        update_metrics(generation_stats, evolution_controller.current_population)\n",
    "        \n",
    "        # Record in generation manager\n",
    "        generation_manager.record_generation(\n",
    "            generation_stats['generation'],\n",
    "            evolution_controller.current_population,\n",
    "            generation_stats\n",
    "        )\n",
    "        \n",
    "        # Display progress\n",
    "        display_progress()\n",
    "        \n",
    "        # Save checkpoint if enabled\n",
    "        if EXPERIMENT_CONFIG['save_checkpoints']:\n",
    "            checkpoint_file = generation_manager.save_checkpoint(\n",
    "                generation_stats['generation'],\n",
    "                evolution_controller.current_population\n",
    "            )\n",
    "            print(f\"üíæ Checkpoint saved: {Path(checkpoint_file).name}\")\n",
    "    \n",
    "    try:\n",
    "        # Run evolution\n",
    "        evolution_results = await evolution_controller.run_evolution(\n",
    "            seed_prompts=SEED_PROMPTS,\n",
    "            progress_callback=progress_callback\n",
    "        )\n",
    "        \n",
    "        return evolution_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Evolution failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# Note: Run this cell to start the evolution\n",
    "print(\"‚ö° Evolution experiment function defined\")\n",
    "print(\"\\nüéØ Ready to run evolution!\")\n",
    "print(\"Execute the next cell to start the experiment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Execute Evolution (Run This Cell to Start!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the evolution experiment\n",
    "print(\"üî• STARTING EVOLUTION EXPERIMENT...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Run the evolution\n",
    "evolution_results = await run_evolution_experiment()\n",
    "\n",
    "if evolution_results:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"üéâ EVOLUTION EXPERIMENT COMPLETED!\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Display final results\n",
    "    print(f\"\\nüìã Final Results:\")\n",
    "    print(f\"  Termination Reason: {evolution_results['termination_reason']}\")\n",
    "    print(f\"  Total Generations: {evolution_results['total_generations']}\")\n",
    "    print(f\"  Final Population Size: {evolution_results['final_population_size']}\")\n",
    "    \n",
    "    # Best genome\n",
    "    best_genome = evolution_results['best_genome']\n",
    "    print(f\"\\nüèÜ Best Genome Found:\")\n",
    "    print(f\"  Generation: {best_genome['generation']}\")\n",
    "    print(f\"  Fitness: {best_genome['fitness']:.4f}\")\n",
    "    print(f\"  Accuracy: {best_genome['accuracy']:.1%}\")\n",
    "    print(f\"  Length: {best_genome['length']} tokens\")\n",
    "    print(f\"  Text: '{best_genome['text']}'\")\n",
    "    \n",
    "    # Evolution statistics\n",
    "    evo_stats = evolution_results['evolution_statistics']\n",
    "    print(f\"\\nüìä Evolution Statistics:\")\n",
    "    print(f\"  Total Time: {evo_stats['total_time_minutes']:.1f} minutes\")\n",
    "    print(f\"  Avg Time per Generation: {evo_stats['avg_time_per_generation']:.1f} seconds\")\n",
    "    \n",
    "    # Save final results\n",
    "    results_file = generation_manager.save_final_results()\n",
    "    print(f\"\\nüíæ Results saved to: {Path(results_file).name}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Evolution experiment failed. Check the error messages above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Results Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of evolution results\n",
    "if evolution_results and evolution_metrics['generations']:\n",
    "    print(\"üìà Evolution Analysis:\")\n",
    "    \n",
    "    # Fitness progression\n",
    "    initial_fitness = evolution_metrics['best_fitness'][0]\n",
    "    final_fitness = evolution_metrics['best_fitness'][-1]\n",
    "    improvement = final_fitness - initial_fitness\n",
    "    \n",
    "    print(f\"\\nüéØ Fitness Progression:\")\n",
    "    print(f\"  Initial Best Fitness: {initial_fitness:.4f}\")\n",
    "    print(f\"  Final Best Fitness: {final_fitness:.4f}\")\n",
    "    print(f\"  Total Improvement: {improvement:.4f} ({improvement/initial_fitness:.1%})\")\n",
    "    \n",
    "    # Accuracy progression\n",
    "    initial_accuracy = evolution_metrics['best_accuracy'][0]\n",
    "    final_accuracy = evolution_metrics['best_accuracy'][-1]\n",
    "    accuracy_improvement = final_accuracy - initial_accuracy\n",
    "    \n",
    "    print(f\"\\nüéØ Accuracy Progression:\")\n",
    "    print(f\"  Initial Best Accuracy: {initial_accuracy:.1%}\")\n",
    "    print(f\"  Final Best Accuracy: {final_accuracy:.1%}\")\n",
    "    print(f\"  Accuracy Improvement: {accuracy_improvement:.1%}\")\n",
    "    \n",
    "    # Generation-by-generation breakdown\n",
    "    print(f\"\\nüìä Generation Breakdown:\")\n",
    "    for i, gen in enumerate(evolution_metrics['generations']):\n",
    "        fitness = evolution_metrics['best_fitness'][i]\n",
    "        accuracy = evolution_metrics['best_accuracy'][i]\n",
    "        print(f\"  Gen {gen:2d}: Fitness={fitness:.4f}, Accuracy={accuracy:.1%}\")\n",
    "    \n",
    "    # Performance statistics\n",
    "    if evolution_results:\n",
    "        evo_stats = evolution_results['evolution_statistics']\n",
    "        \n",
    "        print(f\"\\n‚ö° Performance Statistics:\")\n",
    "        selection_stats = evo_stats.get('selection_stats', {})\n",
    "        mutation_stats = evo_stats.get('mutation_stats', {})\n",
    "        eval_stats = evo_stats.get('evaluation_stats', {})\n",
    "        \n",
    "        print(f\"  Selection - Elite: {selection_stats.get('elite_rate', 0):.1%}, \"\n",
    "              f\"Diverse: {selection_stats.get('diverse_rate', 0):.1%}, \"\n",
    "              f\"Random: {selection_stats.get('random_rate', 0):.1%}\")\n",
    "        \n",
    "        print(f\"  Mutations - Total: {mutation_stats.get('total_mutations', 0)}, \"\n",
    "              f\"Semantic Rate: {mutation_stats.get('semantic_rate', 0):.1%}\")\n",
    "        \n",
    "        print(f\"  Evaluation - Total: {eval_stats.get('total_evaluations', 0)}, \"\n",
    "              f\"Cache Hit Rate: {eval_stats.get('llm_cache_hit_rate', 0):.1%}\")\n",
    "        \n",
    "        print(f\"  Cost - Total: ${eval_stats.get('llm_total_cost_usd', 0):.2f}\")\n",
    "    \n",
    "    # Target achievement\n",
    "    target_accuracy = config.get('experiment.target_accuracy', 0.95)\n",
    "    achieved_target = final_accuracy >= target_accuracy\n",
    "    \n",
    "    print(f\"\\nüéØ Target Achievement:\")\n",
    "    print(f\"  Target Accuracy: {target_accuracy:.1%}\")\n",
    "    print(f\"  Achieved: {'‚úÖ YES' if achieved_target else '‚ùå NO'}\")\n",
    "    print(f\"  Progress: {final_accuracy/target_accuracy:.1%}\")\n",
    "    \n",
    "else:\n",
    "    print(\"No evolution data available for analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Best Genome Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the best genome on the final test set\n",
    "if evolution_results and evolution_metrics['current_best_genome']:\n",
    "    print(\"üß™ Validating Best Genome on Final Test Set...\")\n",
    "    \n",
    "    best_genome_info = evolution_metrics['current_best_genome']\n",
    "    \n",
    "    print(f\"\\nüèÜ Best Genome Details:\")\n",
    "    print(f\"  Found in Generation: {best_genome_info['generation']}\")\n",
    "    print(f\"  Training Fitness: {best_genome_info['fitness']:.4f}\")\n",
    "    print(f\"  Training Accuracy: {best_genome_info['accuracy']:.1%}\")\n",
    "    print(f\"  Prompt Text: '{best_genome_info['text']}'\")\n",
    "    print(f\"  Token Count: {best_genome_info['length']}\")\n",
    "    \n",
    "    # Note: For full validation, you would run the best genome on a held-out test set\n",
    "    print(f\"\\nüìù Validation Notes:\")\n",
    "    print(f\"  - This genome achieved {best_genome_info['accuracy']:.1%} accuracy during evolution\")\n",
    "    print(f\"  - For final validation, test on held-out evaluation set\")\n",
    "    print(f\"  - Consider statistical significance testing\")\n",
    "    print(f\"  - Compare against baseline prompts\")\n",
    "    \n",
    "    # Genome characteristics analysis\n",
    "    prompt_text = best_genome_info['text']\n",
    "    words = prompt_text.split()\n",
    "    \n",
    "    print(f\"\\nüîç Genome Characteristics:\")\n",
    "    print(f\"  Word Count: {len(words)}\")\n",
    "    print(f\"  Character Count: {len(prompt_text)}\")\n",
    "    print(f\"  Avg Word Length: {sum(len(w) for w in words)/len(words):.1f} chars\")\n",
    "    print(f\"  Contains 'step': {'step' in prompt_text.lower()}\")\n",
    "    print(f\"  Contains 'solve': {'solve' in prompt_text.lower()}\")\n",
    "    print(f\"  Contains 'calculate': {'calculate' in prompt_text.lower()}\")\n",
    "    \n",
    "else:\n",
    "    print(\"No best genome available for validation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Experiment Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final experiment summary\n",
    "print(\"üìã EXPERIMENT SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if evolution_results:\n",
    "    # Experiment metadata\n",
    "    experiment_summary = generation_manager.get_experiment_summary()\n",
    "    \n",
    "    print(f\"\\nüß™ Experiment Details:\")\n",
    "    print(f\"  Experiment ID: {experiment_summary.get('experiment_id', 'N/A')}\")\n",
    "    print(f\"  Duration: {experiment_summary.get('elapsed_time_minutes', 0):.1f} minutes\")\n",
    "    print(f\"  Generations: {experiment_summary.get('generations_completed', 0)}\")\n",
    "    print(f\"  Configuration: {EXPERIMENT_CONFIG['population_size']} population, {EXPERIMENT_CONFIG['max_generations']} max generations\")\n",
    "    \n",
    "    # Key achievements\n",
    "    print(f\"\\nüèÜ Key Achievements:\")\n",
    "    print(f\"  Best Fitness: {experiment_summary.get('best_fitness_overall', 0):.4f}\")\n",
    "    print(f\"  Best Accuracy: {experiment_summary.get('best_accuracy_overall', 0):.1%}\")\n",
    "    print(f\"  Fitness Improvement: {experiment_summary.get('fitness_improvement', 0):.4f}\")\n",
    "    \n",
    "    # System performance\n",
    "    if evolution_results.get('evolution_statistics'):\n",
    "        eval_stats = evolution_results['evolution_statistics'].get('evaluation_stats', {})\n",
    "        print(f\"\\n‚ö° System Performance:\")\n",
    "        print(f\"  Total API Calls: {eval_stats.get('llm_total_requests', 0)}\")\n",
    "        print(f\"  Cache Efficiency: {eval_stats.get('llm_cache_hit_rate', 0):.1%}\")\n",
    "        print(f\"  Total Cost: ${eval_stats.get('llm_total_cost_usd', 0):.2f}\")\n",
    "        print(f\"  Avg Time/Generation: {evolution_results['evolution_statistics'].get('avg_time_per_generation', 0):.1f}s\")\n",
    "    \n",
    "    # Files generated\n",
    "    print(f\"\\nüìÅ Generated Files:\")\n",
    "    results_dir = Path('./data/results')\n",
    "    checkpoints_dir = Path('./data/checkpoints')\n",
    "    \n",
    "    if results_dir.exists():\n",
    "        result_files = list(results_dir.glob('*.json'))\n",
    "        print(f\"  Results: {len(result_files)} files in {results_dir}\")\n",
    "    \n",
    "    if checkpoints_dir.exists():\n",
    "        checkpoint_files = list(checkpoints_dir.glob('*.json'))\n",
    "        print(f\"  Checkpoints: {len(checkpoint_files)} files in {checkpoints_dir}\")\n",
    "\n",
    "# Next steps recommendations\n",
    "print(f\"\\nüöÄ Next Steps:\")\n",
    "print(f\"  1. Analyze results in detail using saved JSON files\")\n",
    "print(f\"  2. Validate best genome on held-out test set\")\n",
    "print(f\"  3. Compare against baseline prompts\")\n",
    "print(f\"  4. Run statistical significance tests\")\n",
    "print(f\"  5. Consider hyperparameter tuning for better results\")\n",
    "print(f\"  6. Experiment with different seed prompt strategies\")\n",
    "print(f\"  7. Analyze semantic patterns in successful genomes\")\n",
    "\n",
    "print(f\"\\n‚ú® Experiment completed successfully!\")\n",
    "print(f\"üìä All data saved for further analysis.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
